{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["T9jD_6SeJrF3","5DfCSbbmJrF4","yYzD85nTJrGA","piyLxzj6v07j","280Vbqk-7a8M"]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem Statement \n\nYou need to build a model that is able to classify customer complaints based on the products/services. By doing so, you can segregate these tickets into their relevant categories and, therefore, help in the quick resolution of the issue.\n\nYou will be doing topic modelling on the <b>.json</b> data provided by the company. Since this data is not labelled, you need to apply NMF to analyse patterns and classify tickets into the following five clusters based on their products/services:\n\n* Credit card / Prepaid card\n\n* Bank account services\n\n* Theft/Dispute reporting\n\n* Mortgages/loans\n\n* Others \n\n\nWith the help of topic modelling, you will be able to map each ticket onto its respective department/category. You can then use this data to train any supervised model such as logistic regression, decision tree or random forest. Using this trained model, you can classify any new customer complaint support ticket into its relevant department.","metadata":{"id":"rhR-ZUkwJrFn"}},{"cell_type":"markdown","source":"## Pipelines that needs to be performed:\n\nYou need to perform the following eight major tasks to complete the assignment:\n\n1.  Data loading\n\n2. Text preprocessing\n\n3. Exploratory data analysis (EDA)\n\n4. Feature extraction\n\n5. Topic modelling \n\n6. Model building using supervised learning\n\n7. Model training and evaluation\n\n8. Model inference","metadata":{"id":"mcgXVNyaLUFS"}},{"cell_type":"markdown","source":"## Importing the necessary libraries","metadata":{"id":"JuLFIymAL58u"}},{"cell_type":"code","source":"import json \nimport numpy as np\nimport pandas as pd\nimport re, nltk, spacy, string\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom plotly.offline import plot\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom pprint import pprint","metadata":{"id":"O-Q9pqrcJrFr","execution":{"iopub.status.busy":"2023-07-26T01:50:05.402505Z","iopub.execute_input":"2023-07-26T01:50:05.402872Z","iopub.status.idle":"2023-07-26T01:50:20.783085Z","shell.execute_reply.started":"2023-07-26T01:50:05.402843Z","shell.execute_reply":"2023-07-26T01:50:20.782136Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading the data\n\nThe data is in JSON format and we need to convert it to a dataframe.","metadata":{"id":"KtRLCsNVJrFt"}},{"cell_type":"code","source":"# Opening JSON file \nf = open('/kaggle/input/automatic-ticket-classification/complaints-2021-05-14_08_16.json')# Write the path to your data file and load it \n  \n# returns JSON object as  \n# a dictionary \ndata = json.load(f)\ndf=pd.json_normalize(data)","metadata":{"id":"puVzIf_iJrFt","execution":{"iopub.status.busy":"2023-07-26T01:54:08.421720Z","iopub.execute_input":"2023-07-26T01:54:08.422062Z","iopub.status.idle":"2023-07-26T01:54:11.579588Z","shell.execute_reply.started":"2023-07-26T01:54:08.422034Z","shell.execute_reply":"2023-07-26T01:54:11.578531Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation","metadata":{"id":"_xYpH-sAJrFu"}},{"cell_type":"code","source":"# Inspect the dataframe to understand the given data.\ndf.sample(10)\n","metadata":{"id":"Lf8ufHH5JrFu","execution":{"iopub.status.busy":"2023-07-26T01:54:26.381379Z","iopub.execute_input":"2023-07-26T01:54:26.381741Z","iopub.status.idle":"2023-07-26T01:54:26.419262Z","shell.execute_reply.started":"2023-07-26T01:54:26.381716Z","shell.execute_reply":"2023-07-26T01:54:26.418126Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                    _index      _type      _id  _score    _source.tags  \\\n75472  complaint-public-v2  complaint  2936827     0.0            None   \n47121  complaint-public-v2  complaint  1090592     0.0            None   \n68902  complaint-public-v2  complaint   393159     0.0            None   \n10303  complaint-public-v2  complaint  3586539     0.0            None   \n3864   complaint-public-v2  complaint  2592842     0.0            None   \n30201  complaint-public-v2  complaint  3300964     0.0            None   \n60832  complaint-public-v2  complaint   252273     0.0            None   \n26023  complaint-public-v2  complaint  4333209     0.0            None   \n78043  complaint-public-v2  complaint  1784812     0.0  Older American   \n313    complaint-public-v2  complaint  3344692     0.0            None   \n\n      _source.zip_code _source.complaint_id  \\\n75472            900XX              2936827   \n47121            77406              1090592   \n68902            109XX               393159   \n10303            105XX              3586539   \n3864             303XX              2592842   \n30201            105XX              3300964   \n60832            90280               252273   \n26023            109XX              4333209   \n78043            35810              1784812   \n313              222XX              3344692   \n\n                                           _source.issue  \\\n75472                                Managing an account   \n47121           Loan servicing, payments, escrow account   \n68902           Loan modification,collection,foreclosure   \n10303  Problem with a lender or other company chargin...   \n3864   Advertising and marketing, including promotion...   \n30201  Problem with a credit reporting company's inve...   \n60832           Loan modification,collection,foreclosure   \n26023                                      Fraud or scam   \n78043           Loan servicing, payments, escrow account   \n313                   Other features, terms, or problems   \n\n           _source.date_received _source.state  ...  \\\n75472  2018-06-15T12:00:00-05:00            CA  ...   \n47121  2014-10-27T12:00:00-05:00            TX  ...   \n68902  2013-04-26T12:00:00-05:00            NY  ...   \n10303  2020-03-31T12:00:00-05:00            NY  ...   \n3864   2017-08-02T12:00:00-05:00            GA  ...   \n30201  2019-07-09T12:00:00-05:00            NY  ...   \n60832  2013-01-19T12:00:00-05:00            CA  ...   \n26023  2021-04-28T12:00:00-05:00            NY  ...   \n78043  2016-02-11T12:00:00-05:00            AL  ...   \n313    2019-08-18T12:00:00-05:00            VA  ...   \n\n          _source.company_response       _source.company  \\\n75472  Closed with monetary relief  JPMORGAN CHASE & CO.   \n47121      Closed with explanation  JPMORGAN CHASE & CO.   \n68902  Closed with monetary relief  JPMORGAN CHASE & CO.   \n10303  Closed with monetary relief  JPMORGAN CHASE & CO.   \n3864       Closed with explanation  JPMORGAN CHASE & CO.   \n30201      Closed with explanation  JPMORGAN CHASE & CO.   \n60832      Closed with explanation  JPMORGAN CHASE & CO.   \n26023                  In progress  JPMORGAN CHASE & CO.   \n78043      Closed with explanation  JPMORGAN CHASE & CO.   \n313        Closed with explanation  JPMORGAN CHASE & CO.   \n\n      _source.submitted_via _source.date_sent_to_company  \\\n75472                   Web    2018-06-15T12:00:00-05:00   \n47121              Referral    2014-10-30T12:00:00-05:00   \n68902              Referral    2013-04-29T12:00:00-05:00   \n10303                   Web    2020-03-31T12:00:00-05:00   \n3864                    Web    2017-08-02T12:00:00-05:00   \n30201                   Web    2019-07-09T12:00:00-05:00   \n60832              Referral    2013-01-22T12:00:00-05:00   \n26023                   Web    2021-04-28T12:00:00-05:00   \n78043                 Phone    2016-02-12T12:00:00-05:00   \n313                     Web    2019-08-18T12:00:00-05:00   \n\n      _source.company_public_response  \\\n75472                            None   \n47121                            None   \n68902                            None   \n10303                            None   \n3864                             None   \n30201                            None   \n60832                            None   \n26023                            None   \n78043                            None   \n313                              None   \n\n                              _source.sub_product _source.timely  \\\n75472                            Checking account            Yes   \n47121                              Other mortgage            Yes   \n68902                              Other mortgage            Yes   \n10303                            Checking account            Yes   \n3864   General-purpose credit card or charge card            Yes   \n30201                            Credit reporting            Yes   \n60832                              Other mortgage            Yes   \n26023                Domestic (US) money transfer            Yes   \n78043                 Conventional fixed mortgage            Yes   \n313    General-purpose credit card or charge card            Yes   \n\n                         _source.complaint_what_happened  \\\n75472  On XX/XX/XXXX I deposited {$2500.00} in XXXX b...   \n47121                                                      \n68902                                                      \n10303                                                      \n3864   I originally submitted a complaint ( # XXXX ; ...   \n30201                                                      \n60832                                                      \n26023                                                      \n78043                                                      \n313                                                        \n\n                                       _source.sub_issue  \\\n75472                           Deposits and withdrawals   \n47121                                               None   \n68902                                               None   \n10303                     Transaction was not authorized   \n3864      Didn't receive advertised or promotional terms   \n30201  Difficulty submitting a dispute or getting inf...   \n60832                                               None   \n26023                                               None   \n78043                                               None   \n313                                        Other problem   \n\n      _source.consumer_consent_provided  \n75472                  Consent provided  \n47121                               N/A  \n68902                               N/A  \n10303              Consent not provided  \n3864                   Consent provided  \n30201              Consent not provided  \n60832                               N/A  \n26023                              None  \n78043                               N/A  \n313                Consent not provided  \n\n[10 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_index</th>\n      <th>_type</th>\n      <th>_id</th>\n      <th>_score</th>\n      <th>_source.tags</th>\n      <th>_source.zip_code</th>\n      <th>_source.complaint_id</th>\n      <th>_source.issue</th>\n      <th>_source.date_received</th>\n      <th>_source.state</th>\n      <th>...</th>\n      <th>_source.company_response</th>\n      <th>_source.company</th>\n      <th>_source.submitted_via</th>\n      <th>_source.date_sent_to_company</th>\n      <th>_source.company_public_response</th>\n      <th>_source.sub_product</th>\n      <th>_source.timely</th>\n      <th>_source.complaint_what_happened</th>\n      <th>_source.sub_issue</th>\n      <th>_source.consumer_consent_provided</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75472</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2936827</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>900XX</td>\n      <td>2936827</td>\n      <td>Managing an account</td>\n      <td>2018-06-15T12:00:00-05:00</td>\n      <td>CA</td>\n      <td>...</td>\n      <td>Closed with monetary relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2018-06-15T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td>On XX/XX/XXXX I deposited {$2500.00} in XXXX b...</td>\n      <td>Deposits and withdrawals</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>47121</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>1090592</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>77406</td>\n      <td>1090592</td>\n      <td>Loan servicing, payments, escrow account</td>\n      <td>2014-10-27T12:00:00-05:00</td>\n      <td>TX</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2014-10-30T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>68902</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>393159</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>109XX</td>\n      <td>393159</td>\n      <td>Loan modification,collection,foreclosure</td>\n      <td>2013-04-26T12:00:00-05:00</td>\n      <td>NY</td>\n      <td>...</td>\n      <td>Closed with monetary relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2013-04-29T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>10303</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3586539</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>105XX</td>\n      <td>3586539</td>\n      <td>Problem with a lender or other company chargin...</td>\n      <td>2020-03-31T12:00:00-05:00</td>\n      <td>NY</td>\n      <td>...</td>\n      <td>Closed with monetary relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2020-03-31T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Transaction was not authorized</td>\n      <td>Consent not provided</td>\n    </tr>\n    <tr>\n      <th>3864</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2592842</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>303XX</td>\n      <td>2592842</td>\n      <td>Advertising and marketing, including promotion...</td>\n      <td>2017-08-02T12:00:00-05:00</td>\n      <td>GA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2017-08-02T12:00:00-05:00</td>\n      <td>None</td>\n      <td>General-purpose credit card or charge card</td>\n      <td>Yes</td>\n      <td>I originally submitted a complaint ( # XXXX ; ...</td>\n      <td>Didn't receive advertised or promotional terms</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>30201</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3300964</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>105XX</td>\n      <td>3300964</td>\n      <td>Problem with a credit reporting company's inve...</td>\n      <td>2019-07-09T12:00:00-05:00</td>\n      <td>NY</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2019-07-09T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Credit reporting</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Difficulty submitting a dispute or getting inf...</td>\n      <td>Consent not provided</td>\n    </tr>\n    <tr>\n      <th>60832</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>252273</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>90280</td>\n      <td>252273</td>\n      <td>Loan modification,collection,foreclosure</td>\n      <td>2013-01-19T12:00:00-05:00</td>\n      <td>CA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2013-01-22T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>26023</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>4333209</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>109XX</td>\n      <td>4333209</td>\n      <td>Fraud or scam</td>\n      <td>2021-04-28T12:00:00-05:00</td>\n      <td>NY</td>\n      <td>...</td>\n      <td>In progress</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2021-04-28T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Domestic (US) money transfer</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>78043</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>1784812</td>\n      <td>0.0</td>\n      <td>Older American</td>\n      <td>35810</td>\n      <td>1784812</td>\n      <td>Loan servicing, payments, escrow account</td>\n      <td>2016-02-11T12:00:00-05:00</td>\n      <td>AL</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Phone</td>\n      <td>2016-02-12T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Conventional fixed mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>313</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3344692</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>222XX</td>\n      <td>3344692</td>\n      <td>Other features, terms, or problems</td>\n      <td>2019-08-18T12:00:00-05:00</td>\n      <td>VA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2019-08-18T12:00:00-05:00</td>\n      <td>None</td>\n      <td>General-purpose credit card or charge card</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Other problem</td>\n      <td>Consent not provided</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#print the column names\n","metadata":{"id":"Dwcty-wmJrFw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assign new column names\n","metadata":{"id":"FYCtKXD1JrFw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assign nan in place of blanks in the complaints column\n","metadata":{"id":"grQUPFL5JrFx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove all rows where complaints column is nan\n","metadata":{"id":"Jfxd8VSmJrFy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the text for topic modeling\n\nOnce you have removed all the blank complaints, you need to:\n\n* Make the text lowercase\n* Remove text in square brackets\n* Remove punctuation\n* Remove words containing numbers\n\n\nOnce you have done these cleaning operations you need to perform the following:\n* Lemmatize the texts\n* Extract the POS tags of the lemmatized text and remove all the words which have tags other than NN[tag == \"NN\"].\n","metadata":{"id":"L944HZpsJrFy"}},{"cell_type":"code","source":"# Write your function here to clean the text and remove all the unnecessary elements.\n","metadata":{"id":"qm7SjjSkJrFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your function to Lemmatize the texts\n","metadata":{"id":"zgOu8t8HJrFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create a dataframe('df_clean') that will have only the complaints and the lemmatized complaints \n","metadata":{"id":"uXnN7aa_JrF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"nOiDVvEIJrF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your function to extract the POS tags \n\ndef pos_tag(text):\n  # write your code here\n\n\n\ndf_clean[\"complaint_POS_removed\"] =  #this column should contain lemmatized text with all the words removed which have tags other than NN[tag == \"NN\"].\n","metadata":{"id":"Kk7fc4DuJrF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The clean dataframe should now contain the raw complaint, lemmatized complaint and the complaint after removing POS tags.\ndf_clean","metadata":{"id":"AjxfchvFJrF2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory data analysis to get familiar with the data.\n\nWrite the code in this task to perform the following:\n\n*   Visualise the data according to the 'Complaint' character length\n*   Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n*   Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text. ‘\n\n\n","metadata":{"id":"_7Un1AElJrF2"}},{"cell_type":"code","source":"# Write your code here to visualise the data according to the 'Complaint' character length","metadata":{"id":"q-zaqJF6JrF2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Find the top 40 words by frequency among all the articles after processing the text.","metadata":{"id":"T9jD_6SeJrF3"}},{"cell_type":"code","source":"#Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n","metadata":{"id":"QcfdvtfZJrF3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing -PRON- from the text corpus\ndf_clean['Complaint_clean'] = df_clean['complaint_POS_removed'].str.replace('-PRON-', '')","metadata":{"id":"OkSmc3UaJrF4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text.","metadata":{"id":"5DfCSbbmJrF4"}},{"cell_type":"code","source":"#Write your code here to find the top 30 unigram frequency among the complaints in the cleaned datafram(df_clean). \n","metadata":{"id":"5mbk5DS5JrF4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the unigram frequency\n","metadata":{"id":"YX7fedm1JrF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your code here to find the top 30 bigram frequency among the complaints in the cleaned datafram(df_clean). \n","metadata":{"id":"aV7kD7w8JrF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the bigram frequency","metadata":{"id":"NPnMNIpyJrF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your code here to find the top 30 trigram frequency among the complaints in the cleaned datafram(df_clean). \n","metadata":{"id":"Xkh7vtbtJrF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the trigram frequency","metadata":{"id":"REcVxNfvJrF-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The personal details of customer has been masked in the dataset with xxxx. Let's remove the masked text as this will be of no use for our analysis","metadata":{"id":"yUXzFji0JrF_"}},{"cell_type":"code","source":"df_clean['Complaint_clean'] = df_clean['Complaint_clean'].str.replace('xxxx','')","metadata":{"id":"wKda-a_IJrF_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#All masked texts has been removed\ndf_clean","metadata":{"id":"9UIFk8fQJrF_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction\nConvert the raw texts to a matrix of TF-IDF features\n\n**max_df** is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\"\nmax_df = 0.95 means \"ignore terms that appear in more than 95% of the complaints\"\n\n**min_df** is used for removing terms that appear too infrequently\nmin_df = 2 means \"ignore terms that appear in less than 2 complaints\"","metadata":{"id":"k-I0k0QtJrGA"}},{"cell_type":"code","source":"#Write your code here to initialise the TfidfVectorizer \n\n","metadata":{"id":"Y8fGwaCPJrGA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create a document term matrix using fit_transform\n\nThe contents of a document term matrix are tuples of (complaint_id,token_id) tf-idf score:\nThe tuples that are not there have a tf-idf score of 0","metadata":{"id":"yYzD85nTJrGA"}},{"cell_type":"code","source":"#Write your code here to create the Document Term Matrix by transforming the complaints column present in df_clean.\n","metadata":{"id":"ffzdDpp_JrGB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Topic Modelling using NMF\n\nNon-Negative Matrix Factorization (NMF) is an unsupervised technique so there are no labeling of topics that the model will be trained on. The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative.\n\nIn this task you have to perform the following:\n\n* Find the best number of clusters \n* Apply the best number to create word clusters\n* Inspect & validate the correction of each cluster wrt the complaints \n* Correct the labels if needed \n* Map the clusters to topics/cluster names","metadata":{"id":"7Q9lwvNEJrGB"}},{"cell_type":"code","source":"from sklearn.decomposition import NMF","metadata":{"id":"amLT4omWJrGB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Manual Topic Modeling\nYou need to do take the trial & error approach to find the best num of topics for your NMF model.\n\nThe only parameter that is required is the number of components i.e. the number of topics we want. This is the most crucial step in the whole topic modeling process and will greatly affect how good your final topics are.","metadata":{"id":"0wYR1xUTJrGD"}},{"cell_type":"code","source":"#Load your nmf_model with the n_components i.e 5\nnum_topics = #write the value you want to test out\n\n#keep the random_state =40\nnmf_model = #write your code here","metadata":{"id":"sgd2A6bhJrGD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nmf_model.fit(dtm)\nlen(tfidf.get_feature_names())","metadata":{"id":"VPMDYbt_JrGE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the Top15 words for each of the topics\n","metadata":{"id":"16kRfat5JrGE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create the best topic for each complaint in terms of integer value 0,1,2,3 & 4\n\n","metadata":{"id":"0OIT7LmFJrGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assign the best topic to each of the cmplaints in Topic Column\n\ndf_clean['Topic'] = #write your code to assign topics to each rows.","metadata":{"id":"peyYv-ORJrGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean.head()","metadata":{"id":"fLh_Gf3nJrGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the first 5 Complaint for each of the Topics\ndf_clean=df_clean.groupby('Topic').head(5)\ndf_clean.sort_values('Topic')","metadata":{"id":"aQKpufSPJrGG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### After evaluating the mapping, if the topics assigned are correct then assign these names to the relevant topic:\n* Bank Account services\n* Credit card or prepaid card\n* Theft/Dispute Reporting\n* Mortgage/Loan\n* Others","metadata":{"id":"piyLxzj6v07j"}},{"cell_type":"code","source":"#Create the dictionary of Topic names and Topics\n\nTopic_names = {   }\n#Replace Topics with Topic Names\ndf_clean['Topic'] = df_clean['Topic'].map(Topic_names)","metadata":{"id":"TWpwDG4RJrGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"-2ULY5K6JrGG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supervised model to predict any new complaints to the relevant Topics.\n\nYou have now build the model to create the topics for each complaints.Now in the below section you will use them to classify any new complaints.\n\nSince you will be using supervised learning technique we have to convert the topic names to numbers(numpy arrays only understand numbers)","metadata":{"id":"7Mu0QBOcJrGH"}},{"cell_type":"code","source":"#Create the dictionary again of Topic names and Topics\n\nTopic_names = {   }\n#Replace Topics with Topic Names\ndf_clean['Topic'] = df_clean['Topic'].map(Topic_names)","metadata":{"id":"_U8J3J8wJrGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"BWIgJUkQJrGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Keep the columns\"complaint_what_happened\" & \"Topic\" only in the new dataframe --> training_data\ntraining_data=","metadata":{"id":"Xx-FrbkWJrGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data","metadata":{"id":"lVg2pa12JrGI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####Apply the supervised models on the training data created. In this process, you have to do the following:\n* Create the vector counts using Count Vectoriser\n* Transform the word vecotr to tf-idf\n* Create the train & test data using the train_test_split on the tf-idf & topics\n","metadata":{"id":"280Vbqk-7a8M"}},{"cell_type":"code","source":"\n#Write your code to get the Vector count\n\n\n#Write your code here to transform the word vector to tf-idf","metadata":{"id":"oUlQpgkzJrGI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You have to try atleast 3 models on the train & test data from these options:\n* Logistic regression\n* Decision Tree\n* Random Forest\n* Naive Bayes (optional)\n\n**Using the required evaluation metrics judge the tried models and select the ones performing the best**","metadata":{"id":"uMU3vj6w-wqL"}},{"cell_type":"code","source":"# Write your code here to build any 3 models and evaluate them using the required metrics\n\n\n\n","metadata":{"id":"udLHpPsZJrGI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"N2OznsObJrGP"},"execution_count":null,"outputs":[]}]}