{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem Statement \n\nYou need to build a model that is able to classify customer complaints based on the products/services. By doing so, you can segregate these tickets into their relevant categories and, therefore, help in the quick resolution of the issue.\n\nYou will be doing topic modelling on the <b>.json</b> data provided by the company. Since this data is not labelled, you need to apply NMF to analyse patterns and classify tickets into the following five clusters based on their products/services:\n\n* Credit card / Prepaid card\n\n* Bank account services\n\n* Theft/Dispute reporting\n\n* Mortgages/loans\n\n* Others \n\n\nWith the help of topic modelling, you will be able to map each ticket onto its respective department/category. You can then use this data to train any supervised model such as logistic regression, decision tree or random forest. Using this trained model, you can classify any new customer complaint support ticket into its relevant department.","metadata":{"id":"rhR-ZUkwJrFn"}},{"cell_type":"markdown","source":"## Pipelines that needs to be performed:\n\nYou need to perform the following eight major tasks to complete the assignment:\n\n1.  Data loading\n\n2. Text preprocessing\n\n3. Exploratory data analysis (EDA)\n\n4. Feature extraction\n\n5. Topic modelling \n\n6. Model building using supervised learning\n\n7. Model training and evaluation\n\n8. Model inference","metadata":{"id":"mcgXVNyaLUFS"}},{"cell_type":"markdown","source":"## Importing the necessary libraries","metadata":{"id":"JuLFIymAL58u"}},{"cell_type":"code","source":"import json \nimport numpy as np\nimport pandas as pd\nimport re, nltk, spacy, string\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom plotly.offline import plot\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom pprint import pprint\n\nfrom nltk.corpus import wordnet\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.probability import FreqDist","metadata":{"id":"O-Q9pqrcJrFr","execution":{"iopub.status.busy":"2023-07-31T02:20:07.460910Z","iopub.execute_input":"2023-07-31T02:20:07.461520Z","iopub.status.idle":"2023-07-31T02:20:08.676598Z","shell.execute_reply.started":"2023-07-31T02:20:07.461478Z","shell.execute_reply":"2023-07-31T02:20:08.675159Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:20:08.679711Z","iopub.execute_input":"2023-07-31T02:20:08.680268Z","iopub.status.idle":"2023-07-31T02:20:08.690507Z","shell.execute_reply.started":"2023-07-31T02:20:08.680223Z","shell.execute_reply":"2023-07-31T02:20:08.689164Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:20:08.691942Z","iopub.execute_input":"2023-07-31T02:20:08.692349Z","iopub.status.idle":"2023-07-31T02:21:59.996012Z","shell.execute_reply.started":"2023-07-31T02:20:08.692304Z","shell.execute_reply":"2023-07-31T02:21:59.994317Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading the data\n\nThe data is in JSON format and we need to convert it to a dataframe.","metadata":{"id":"KtRLCsNVJrFt"}},{"cell_type":"code","source":"# Opening JSON file \nf = open('/kaggle/input/automatic-ticket-classification/complaints-2021-05-14_08_16.json')# Write the path to your data file and load it \n  \n# returns JSON object as  \n# a dictionary \ndata = json.load(f)\ndf=pd.json_normalize(data)","metadata":{"id":"puVzIf_iJrFt","execution":{"iopub.status.busy":"2023-07-31T02:21:59.998583Z","iopub.execute_input":"2023-07-31T02:21:59.999008Z","iopub.status.idle":"2023-07-31T02:22:04.903395Z","shell.execute_reply.started":"2023-07-31T02:21:59.998971Z","shell.execute_reply":"2023-07-31T02:22:04.901944Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation","metadata":{"id":"_xYpH-sAJrFu"}},{"cell_type":"code","source":"# Inspect the dataframe to understand the given data.\ndf.sample(10)\n","metadata":{"id":"Lf8ufHH5JrFu","execution":{"iopub.status.busy":"2023-07-31T02:22:04.908059Z","iopub.execute_input":"2023-07-31T02:22:04.908502Z","iopub.status.idle":"2023-07-31T02:22:04.945707Z","shell.execute_reply.started":"2023-07-31T02:22:04.908467Z","shell.execute_reply":"2023-07-31T02:22:04.944285Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"                    _index      _type      _id  _score  \\\n20682  complaint-public-v2  complaint  4242096     0.0   \n66138  complaint-public-v2  complaint  2079539     0.0   \n25562  complaint-public-v2  complaint  3797044     0.0   \n43831  complaint-public-v2  complaint  2705796     0.0   \n21217  complaint-public-v2  complaint  3350123     0.0   \n25196  complaint-public-v2  complaint  3997521     0.0   \n7987   complaint-public-v2  complaint  3448442     0.0   \n49910  complaint-public-v2  complaint  1037094     0.0   \n43662  complaint-public-v2  complaint  2700861     0.0   \n75165  complaint-public-v2  complaint  2992154     0.0   \n\n                        _source.tags _source.zip_code _source.complaint_id  \\\n20682                           None            770XX              4242096   \n66138                           None             None              2079539   \n25562                           None            114XX              3797044   \n43831                           None             None              2705796   \n21217                           None            100XX              3350123   \n25196  Older American, Servicemember            34609              3997521   \n7987                   Servicemember             None              3448442   \n49910                           None            92115              1037094   \n43662                           None            432XX              2700861   \n75165                           None            331XX              2992154   \n\n                                           _source.issue  \\\n20682  Unauthorized transactions or other transaction...   \n66138                    Disclosure verification of debt   \n25562                  Attempts to collect debt not owed   \n43831                                Managing an account   \n21217               Incorrect information on your report   \n25196                                Managing an account   \n7987                                 Managing an account   \n49910                               APR or interest rate   \n43662                              Getting a credit card   \n75165    Problem with a purchase shown on your statement   \n\n           _source.date_received _source.state  ...  \\\n20682  2021-03-24T12:00:00-05:00            TX  ...   \n66138  2016-08-25T12:00:00-05:00          None  ...   \n25562  2020-08-14T12:00:00-05:00            NY  ...   \n43831  2017-10-18T12:00:00-05:00            WA  ...   \n21217  2019-08-22T12:00:00-05:00            NY  ...   \n25196  2020-12-08T12:00:00-05:00            FL  ...   \n7987   2019-11-23T12:00:00-05:00            CO  ...   \n49910  2014-09-19T12:00:00-05:00            CA  ...   \n43662  2017-10-13T12:00:00-05:00            OH  ...   \n75165  2018-08-15T12:00:00-05:00            FL  ...   \n\n          _source.company_response       _source.company  \\\n20682      Closed with explanation  JPMORGAN CHASE & CO.   \n66138      Closed with explanation  JPMORGAN CHASE & CO.   \n25562      Closed with explanation  JPMORGAN CHASE & CO.   \n43831      Closed with explanation  JPMORGAN CHASE & CO.   \n21217      Closed with explanation  JPMORGAN CHASE & CO.   \n25196      Closed with explanation  JPMORGAN CHASE & CO.   \n7987   Closed with monetary relief  JPMORGAN CHASE & CO.   \n49910      Closed with explanation  JPMORGAN CHASE & CO.   \n43662      Closed with explanation  JPMORGAN CHASE & CO.   \n75165      Closed with explanation  JPMORGAN CHASE & CO.   \n\n      _source.submitted_via _source.date_sent_to_company  \\\n20682                   Web    2021-03-24T12:00:00-05:00   \n66138           Postal mail    2016-08-29T12:00:00-05:00   \n25562                   Web    2020-08-24T12:00:00-05:00   \n43831                   Web    2017-10-18T12:00:00-05:00   \n21217                   Web    2019-08-22T12:00:00-05:00   \n25196                 Phone    2020-12-08T12:00:00-05:00   \n7987                    Web    2019-11-23T12:00:00-05:00   \n49910                   Web    2014-09-19T12:00:00-05:00   \n43662                   Web    2017-10-13T12:00:00-05:00   \n75165                   Web    2018-08-15T12:00:00-05:00   \n\n      _source.company_public_response  \\\n20682                            None   \n66138                            None   \n25562                            None   \n43831                            None   \n21217                            None   \n25196                            None   \n7987                             None   \n49910                            None   \n43662                            None   \n75165                            None   \n\n                              _source.sub_product _source.timely  \\\n20682                    Mobile or digital wallet            Yes   \n66138                                 Credit card            Yes   \n25562                            Credit card debt            Yes   \n43831                            Checking account            Yes   \n21217                            Credit reporting            Yes   \n25196                            Checking account            Yes   \n7987                             Checking account            Yes   \n49910                                        None            Yes   \n43662                           Store credit card            Yes   \n75165  General-purpose credit card or charge card            Yes   \n\n                         _source.complaint_what_happened  \\\n20682                                                      \n66138                                                      \n25562  i did a debt resolution program back in XXXX o...   \n43831                                                      \n21217  I have been going back and forth with chase si...   \n25196                                                      \n7987   I was approached yesterday on XX/XX/19, by a w...   \n49910                                                      \n43662  Chase bank ohio applay Credit Cards. Chase fre...   \n75165  Purchase Date Of XXXX XXXX  Services : XX/XX/2...   \n\n                                       _source.sub_issue  \\\n20682                                               None   \n66138               Not given enough info to verify debt   \n25562                                      Debt was paid   \n43831                  Problem using a debit or ATM card   \n21217                     Personal information incorrect   \n25196                           Deposits and withdrawals   \n7987                            Deposits and withdrawals   \n49910                                               None   \n43662                                 Application denied   \n75165  Credit card company isn't resolving a dispute ...   \n\n      _source.consumer_consent_provided  \n20682                              None  \n66138                               N/A  \n25562                  Consent provided  \n43831                             Other  \n21217                  Consent provided  \n25196                               N/A  \n7987                   Consent provided  \n49910                               N/A  \n43662                  Consent provided  \n75165                  Consent provided  \n\n[10 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_index</th>\n      <th>_type</th>\n      <th>_id</th>\n      <th>_score</th>\n      <th>_source.tags</th>\n      <th>_source.zip_code</th>\n      <th>_source.complaint_id</th>\n      <th>_source.issue</th>\n      <th>_source.date_received</th>\n      <th>_source.state</th>\n      <th>...</th>\n      <th>_source.company_response</th>\n      <th>_source.company</th>\n      <th>_source.submitted_via</th>\n      <th>_source.date_sent_to_company</th>\n      <th>_source.company_public_response</th>\n      <th>_source.sub_product</th>\n      <th>_source.timely</th>\n      <th>_source.complaint_what_happened</th>\n      <th>_source.sub_issue</th>\n      <th>_source.consumer_consent_provided</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20682</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>4242096</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>770XX</td>\n      <td>4242096</td>\n      <td>Unauthorized transactions or other transaction...</td>\n      <td>2021-03-24T12:00:00-05:00</td>\n      <td>TX</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2021-03-24T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Mobile or digital wallet</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>66138</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2079539</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2079539</td>\n      <td>Disclosure verification of debt</td>\n      <td>2016-08-25T12:00:00-05:00</td>\n      <td>None</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Postal mail</td>\n      <td>2016-08-29T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Credit card</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Not given enough info to verify debt</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>25562</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3797044</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>114XX</td>\n      <td>3797044</td>\n      <td>Attempts to collect debt not owed</td>\n      <td>2020-08-14T12:00:00-05:00</td>\n      <td>NY</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2020-08-24T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Credit card debt</td>\n      <td>Yes</td>\n      <td>i did a debt resolution program back in XXXX o...</td>\n      <td>Debt was paid</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>43831</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2705796</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2705796</td>\n      <td>Managing an account</td>\n      <td>2017-10-18T12:00:00-05:00</td>\n      <td>WA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2017-10-18T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Problem using a debit or ATM card</td>\n      <td>Other</td>\n    </tr>\n    <tr>\n      <th>21217</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3350123</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>100XX</td>\n      <td>3350123</td>\n      <td>Incorrect information on your report</td>\n      <td>2019-08-22T12:00:00-05:00</td>\n      <td>NY</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2019-08-22T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Credit reporting</td>\n      <td>Yes</td>\n      <td>I have been going back and forth with chase si...</td>\n      <td>Personal information incorrect</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>25196</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3997521</td>\n      <td>0.0</td>\n      <td>Older American, Servicemember</td>\n      <td>34609</td>\n      <td>3997521</td>\n      <td>Managing an account</td>\n      <td>2020-12-08T12:00:00-05:00</td>\n      <td>FL</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Phone</td>\n      <td>2020-12-08T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Deposits and withdrawals</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>7987</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3448442</td>\n      <td>0.0</td>\n      <td>Servicemember</td>\n      <td>None</td>\n      <td>3448442</td>\n      <td>Managing an account</td>\n      <td>2019-11-23T12:00:00-05:00</td>\n      <td>CO</td>\n      <td>...</td>\n      <td>Closed with monetary relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2019-11-23T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td>I was approached yesterday on XX/XX/19, by a w...</td>\n      <td>Deposits and withdrawals</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>49910</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>1037094</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>92115</td>\n      <td>1037094</td>\n      <td>APR or interest rate</td>\n      <td>2014-09-19T12:00:00-05:00</td>\n      <td>CA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2014-09-19T12:00:00-05:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>43662</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2700861</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>432XX</td>\n      <td>2700861</td>\n      <td>Getting a credit card</td>\n      <td>2017-10-13T12:00:00-05:00</td>\n      <td>OH</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2017-10-13T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Store credit card</td>\n      <td>Yes</td>\n      <td>Chase bank ohio applay Credit Cards. Chase fre...</td>\n      <td>Application denied</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>75165</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2992154</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>331XX</td>\n      <td>2992154</td>\n      <td>Problem with a purchase shown on your statement</td>\n      <td>2018-08-15T12:00:00-05:00</td>\n      <td>FL</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2018-08-15T12:00:00-05:00</td>\n      <td>None</td>\n      <td>General-purpose credit card or charge card</td>\n      <td>Yes</td>\n      <td>Purchase Date Of XXXX XXXX  Services : XX/XX/2...</td>\n      <td>Credit card company isn't resolving a dispute ...</td>\n      <td>Consent provided</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:04.948968Z","iopub.execute_input":"2023-07-31T02:22:04.949845Z","iopub.status.idle":"2023-07-31T02:22:04.958696Z","shell.execute_reply.started":"2023-07-31T02:22:04.949791Z","shell.execute_reply":"2023-07-31T02:22:04.957450Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"(78313, 22)"},"metadata":{}}]},{"cell_type":"code","source":"#print the column names\ndf.columns","metadata":{"id":"Dwcty-wmJrFw","execution":{"iopub.status.busy":"2023-07-31T02:22:04.960291Z","iopub.execute_input":"2023-07-31T02:22:04.960714Z","iopub.status.idle":"2023-07-31T02:22:04.972480Z","shell.execute_reply.started":"2023-07-31T02:22:04.960681Z","shell.execute_reply":"2023-07-31T02:22:04.970951Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"Index(['_index', '_type', '_id', '_score', '_source.tags', '_source.zip_code',\n       '_source.complaint_id', '_source.issue', '_source.date_received',\n       '_source.state', '_source.consumer_disputed', '_source.product',\n       '_source.company_response', '_source.company', '_source.submitted_via',\n       '_source.date_sent_to_company', '_source.company_public_response',\n       '_source.sub_product', '_source.timely',\n       '_source.complaint_what_happened', '_source.sub_issue',\n       '_source.consumer_consent_provided'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"#Assign new column names\nfor column_name in df.columns:\n    cleaned_column_name = re.sub('^_', '', column_name)\n    cleaned_column_name = re.sub('^source\\.', '', cleaned_column_name)\n    df.rename(columns={column_name: cleaned_column_name}, inplace=True)","metadata":{"id":"FYCtKXD1JrFw","execution":{"iopub.status.busy":"2023-07-31T02:25:22.225667Z","iopub.execute_input":"2023-07-31T02:25:22.226244Z","iopub.status.idle":"2023-07-31T02:25:22.245355Z","shell.execute_reply.started":"2023-07-31T02:25:22.226195Z","shell.execute_reply":"2023-07-31T02:25:22.243934Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:25:23.764526Z","iopub.execute_input":"2023-07-31T02:25:23.765090Z","iopub.status.idle":"2023-07-31T02:25:23.774676Z","shell.execute_reply.started":"2023-07-31T02:25:23.765050Z","shell.execute_reply":"2023-07-31T02:25:23.773400Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"Index(['index', 'type', 'id', 'score', 'tags', 'zip_code', 'complaint_id',\n       'issue', 'date_received', 'state', 'consumer_disputed', 'product',\n       'company_response', 'company', 'submitted_via', 'date_sent_to_company',\n       'company_public_response', 'sub_product', 'timely',\n       'complaint_what_happened', 'sub_issue', 'consumer_consent_provided'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.014600Z","iopub.execute_input":"2023-07-31T02:22:05.015583Z","iopub.status.idle":"2023-07-31T02:22:05.055517Z","shell.execute_reply.started":"2023-07-31T02:22:05.015547Z","shell.execute_reply":"2023-07-31T02:22:05.054149Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"                    _index      _type      _id  _score   _source.tags  \\\n58025  complaint-public-v2  complaint  2805412     0.0           None   \n17041  complaint-public-v2  complaint  2822777     0.0           None   \n30176  complaint-public-v2  complaint  3274115     0.0           None   \n22024  complaint-public-v2  complaint  3196099     0.0  Servicemember   \n53296  complaint-public-v2  complaint  1651159     0.0           None   \n42473  complaint-public-v2  complaint    40720     0.0           None   \n48352  complaint-public-v2  complaint   192971     0.0  Servicemember   \n23812  complaint-public-v2  complaint   644391     0.0           None   \n76054  complaint-public-v2  complaint  2885647     0.0           None   \n25811  complaint-public-v2  complaint  3453244     0.0           None   \n\n      _source.zip_code _source.complaint_id  \\\n58025            070XX              2805412   \n17041            30008              2822777   \n30176            750XX              3274115   \n22024            30016              3196099   \n53296            89141              1651159   \n42473            598XX                40720   \n48352            490XX               192971   \n23812            949XX               644391   \n76054            77004              2885647   \n25811            27950              3453244   \n\n                                  _source.issue      _source.date_received  \\\n58025                      Closing your account  2018-02-06T12:00:00-05:00   \n17041                       Managing an account  2018-02-22T12:00:00-05:00   \n30176       Problem with a purchase or transfer  2019-06-13T12:00:00-05:00   \n22024                Struggling to pay mortgage  2019-03-30T12:00:00-05:00   \n53296  Loan modification,collection,foreclosure  2015-11-12T12:00:00-05:00   \n42473  Loan servicing, payments, escrow account  2012-03-25T12:00:00-05:00   \n48352                          Billing disputes  2012-11-19T12:00:00-05:00   \n23812                            Payoff process  2013-12-18T12:00:00-05:00   \n76054               Improper use of your report  2018-04-23T12:00:00-05:00   \n25811            Trouble during payment process  2019-11-29T12:00:00-05:00   \n\n      _source.state  ... _source.company_response       _source.company  \\\n58025            NJ  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n17041            GA  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n30176            TX  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n22024            GA  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n53296            NV  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n42473            MT  ...    Closed without relief  JPMORGAN CHASE & CO.   \n48352            MI  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n23812            CA  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n76054            TX  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n25811            NC  ...  Closed with explanation  JPMORGAN CHASE & CO.   \n\n      _source.submitted_via _source.date_sent_to_company  \\\n58025                   Web    2018-02-06T12:00:00-05:00   \n17041           Postal mail    2018-02-22T12:00:00-05:00   \n30176                   Web    2019-06-13T12:00:00-05:00   \n22024                   Web    2019-03-30T12:00:00-05:00   \n53296                   Web    2015-11-16T12:00:00-05:00   \n42473              Referral    2012-04-05T12:00:00-05:00   \n48352                   Web    2012-11-19T12:00:00-05:00   \n23812                   Web    2013-12-17T12:00:00-05:00   \n76054              Referral    2018-04-24T12:00:00-05:00   \n25811                   Web    2019-12-04T12:00:00-05:00   \n\n      _source.company_public_response  \\\n58025                            None   \n17041                            None   \n30176                            None   \n22024                            None   \n53296                            None   \n42473                            None   \n48352                            None   \n23812                            None   \n76054                            None   \n25811                            None   \n\n                              _source.sub_product _source.timely  \\\n58025  General-purpose credit card or charge card            Yes   \n17041            Other banking product or service            Yes   \n30176                General-purpose prepaid card            Yes   \n22024                                FHA mortgage            Yes   \n53296                                FHA mortgage            Yes   \n42473                              Other mortgage            Yes   \n48352                                        None            Yes   \n23812                                        None            Yes   \n76054                            Credit reporting            Yes   \n25811                      Other type of mortgage            Yes   \n\n                         _source.complaint_what_happened  \\\n58025                                                      \n17041                                                      \n30176  I AM INSTANTLY PUSHED OVER TO CORPORATE WHO I ...   \n22024                                                      \n53296                                                      \n42473                                                      \n48352                                                      \n23812                                                      \n76054                                                      \n25811                                                      \n\n                                       _source.sub_issue  \\\n58025                        Company closed your account   \n17041                           Deposits and withdrawals   \n30176  Card company isn't resolving a dispute about a...   \n22024                                               None   \n53296                                               None   \n42473                                               None   \n48352                                               None   \n23812                                               None   \n76054  Credit inquiries on your report that you don't...   \n25811                                               None   \n\n      _source.consumer_consent_provided  \n58025              Consent not provided  \n17041                               N/A  \n30176                  Consent provided  \n22024              Consent not provided  \n53296              Consent not provided  \n42473                               N/A  \n48352                               N/A  \n23812                               N/A  \n76054                               N/A  \n25811                 Consent withdrawn  \n\n[10 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_index</th>\n      <th>_type</th>\n      <th>_id</th>\n      <th>_score</th>\n      <th>_source.tags</th>\n      <th>_source.zip_code</th>\n      <th>_source.complaint_id</th>\n      <th>_source.issue</th>\n      <th>_source.date_received</th>\n      <th>_source.state</th>\n      <th>...</th>\n      <th>_source.company_response</th>\n      <th>_source.company</th>\n      <th>_source.submitted_via</th>\n      <th>_source.date_sent_to_company</th>\n      <th>_source.company_public_response</th>\n      <th>_source.sub_product</th>\n      <th>_source.timely</th>\n      <th>_source.complaint_what_happened</th>\n      <th>_source.sub_issue</th>\n      <th>_source.consumer_consent_provided</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>58025</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2805412</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>070XX</td>\n      <td>2805412</td>\n      <td>Closing your account</td>\n      <td>2018-02-06T12:00:00-05:00</td>\n      <td>NJ</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2018-02-06T12:00:00-05:00</td>\n      <td>None</td>\n      <td>General-purpose credit card or charge card</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Company closed your account</td>\n      <td>Consent not provided</td>\n    </tr>\n    <tr>\n      <th>17041</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2822777</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>30008</td>\n      <td>2822777</td>\n      <td>Managing an account</td>\n      <td>2018-02-22T12:00:00-05:00</td>\n      <td>GA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Postal mail</td>\n      <td>2018-02-22T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other banking product or service</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Deposits and withdrawals</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>30176</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3274115</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>750XX</td>\n      <td>3274115</td>\n      <td>Problem with a purchase or transfer</td>\n      <td>2019-06-13T12:00:00-05:00</td>\n      <td>TX</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2019-06-13T12:00:00-05:00</td>\n      <td>None</td>\n      <td>General-purpose prepaid card</td>\n      <td>Yes</td>\n      <td>I AM INSTANTLY PUSHED OVER TO CORPORATE WHO I ...</td>\n      <td>Card company isn't resolving a dispute about a...</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>22024</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3196099</td>\n      <td>0.0</td>\n      <td>Servicemember</td>\n      <td>30016</td>\n      <td>3196099</td>\n      <td>Struggling to pay mortgage</td>\n      <td>2019-03-30T12:00:00-05:00</td>\n      <td>GA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2019-03-30T12:00:00-05:00</td>\n      <td>None</td>\n      <td>FHA mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>Consent not provided</td>\n    </tr>\n    <tr>\n      <th>53296</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>1651159</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>89141</td>\n      <td>1651159</td>\n      <td>Loan modification,collection,foreclosure</td>\n      <td>2015-11-12T12:00:00-05:00</td>\n      <td>NV</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2015-11-16T12:00:00-05:00</td>\n      <td>None</td>\n      <td>FHA mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>Consent not provided</td>\n    </tr>\n    <tr>\n      <th>42473</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>40720</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>598XX</td>\n      <td>40720</td>\n      <td>Loan servicing, payments, escrow account</td>\n      <td>2012-03-25T12:00:00-05:00</td>\n      <td>MT</td>\n      <td>...</td>\n      <td>Closed without relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2012-04-05T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>48352</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>192971</td>\n      <td>0.0</td>\n      <td>Servicemember</td>\n      <td>490XX</td>\n      <td>192971</td>\n      <td>Billing disputes</td>\n      <td>2012-11-19T12:00:00-05:00</td>\n      <td>MI</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2012-11-19T12:00:00-05:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>23812</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>644391</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>949XX</td>\n      <td>644391</td>\n      <td>Payoff process</td>\n      <td>2013-12-18T12:00:00-05:00</td>\n      <td>CA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2013-12-17T12:00:00-05:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>76054</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2885647</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>77004</td>\n      <td>2885647</td>\n      <td>Improper use of your report</td>\n      <td>2018-04-23T12:00:00-05:00</td>\n      <td>TX</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2018-04-24T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Credit reporting</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Credit inquiries on your report that you don't...</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>25811</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3453244</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>27950</td>\n      <td>3453244</td>\n      <td>Trouble during payment process</td>\n      <td>2019-11-29T12:00:00-05:00</td>\n      <td>NC</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2019-12-04T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other type of mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>Consent withdrawn</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"(df.complaint_what_happened == \"\").sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:25:33.082267Z","iopub.execute_input":"2023-07-31T02:25:33.082804Z","iopub.status.idle":"2023-07-31T02:25:33.110550Z","shell.execute_reply.started":"2023-07-31T02:25:33.082756Z","shell.execute_reply":"2023-07-31T02:25:33.109010Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"57241"},"metadata":{}}]},{"cell_type":"code","source":"#Assign nan in place of blanks in the complaints column\ndf[df.complaint_what_happened == \"\"] = np.nan ","metadata":{"id":"grQUPFL5JrFx","execution":{"iopub.status.busy":"2023-07-31T02:22:05.176809Z","iopub.status.idle":"2023-07-31T02:22:05.177300Z","shell.execute_reply.started":"2023-07-31T02:22:05.177077Z","shell.execute_reply":"2023-07-31T02:22:05.177097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df.complaint_what_happened == \"\").sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.179945Z","iopub.status.idle":"2023-07-31T02:22:05.180555Z","shell.execute_reply.started":"2023-07-31T02:22:05.180248Z","shell.execute_reply":"2023-07-31T02:22:05.180276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df.complaint_what_happened == np.nan).sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.183024Z","iopub.status.idle":"2023-07-31T02:22:05.183616Z","shell.execute_reply.started":"2023-07-31T02:22:05.183314Z","shell.execute_reply":"2023-07-31T02:22:05.183343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove all rows where complaints column is nan\ndf.dropna(subset=['complaint_what_happened'], inplace=True)","metadata":{"id":"Jfxd8VSmJrFy","execution":{"iopub.status.busy":"2023-07-31T02:22:05.185306Z","iopub.status.idle":"2023-07-31T02:22:05.185921Z","shell.execute_reply.started":"2023-07-31T02:22:05.185584Z","shell.execute_reply":"2023-07-31T02:22:05.185612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.189285Z","iopub.status.idle":"2023-07-31T02:22:05.189881Z","shell.execute_reply.started":"2023-07-31T02:22:05.189566Z","shell.execute_reply":"2023-07-31T02:22:05.189603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the text for topic modeling\n\nOnce you have removed all the blank complaints, you need to:\n\n* Make the text lowercase\n* Remove text in square brackets\n* Remove punctuation\n* Remove words containing numbers\n\n\nOnce you have done these cleaning operations you need to perform the following:\n* Lemmatize the texts\n* Extract the POS tags of the lemmatized text and remove all the words which have tags other than NN[tag == \"NN\"].\n","metadata":{"id":"L944HZpsJrFy"}},{"cell_type":"code","source":"# Write your function here to clean the text and remove all the unnecessary elements.\ndef clean_text(text):\n    # Make the text lowercase\n    text = text.lower()\n    \n    # Remove text in square brackets using regular expression\n    text = re.sub(r'\\[.*?\\]', '', text)\n    \n    # Remove punctuation using string library\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    \n    # Remove words containing numbers using regular expression\n    text = re.sub(r'\\w*\\d\\w*', '', text)\n    \n    return text","metadata":{"id":"qm7SjjSkJrFz","execution":{"iopub.status.busy":"2023-07-31T02:22:05.191016Z","iopub.status.idle":"2023-07-31T02:22:05.191555Z","shell.execute_reply.started":"2023-07-31T02:22:05.191278Z","shell.execute_reply":"2023-07-31T02:22:05.191306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your function to Lemmatize the texts\ndef lemmatize_text(text):\n    # Tokenize the text into words\n    words = word_tokenize(text.lower())\n    \n    # Initialize the WordNet Lemmatizer\n    lemmatizer = WordNetLemmatizer()\n    \n    # Lemmatize each word using its part of speech (POS)\n    lemmatized_words = []\n    for word, pos in nltk.pos_tag(words):\n        pos_letter = pos[0].lower() if pos[0].lower() in ['a', 'r', 'n', 'v'] else 'n'\n        lemma = lemmatizer.lemmatize(word, pos=pos_letter)\n        lemmatized_words.append(lemma)\n    \n    # Join the lemmatized words back into a sentence\n    lemmatized_text = ' '.join(lemmatized_words)\n    \n    return lemmatized_text","metadata":{"id":"zgOu8t8HJrFz","execution":{"iopub.status.busy":"2023-07-31T02:22:05.193262Z","iopub.status.idle":"2023-07-31T02:22:05.193823Z","shell.execute_reply.started":"2023-07-31T02:22:05.193525Z","shell.execute_reply":"2023-07-31T02:22:05.193550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['cleaned_complaints'] = df['complaint_what_happened'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.195810Z","iopub.status.idle":"2023-07-31T02:22:05.196401Z","shell.execute_reply.started":"2023-07-31T02:22:05.196092Z","shell.execute_reply":"2023-07-31T02:22:05.196117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ntqdm.pandas()\ndf['lemmatized_complaints'] = df['cleaned_complaints'].progress_apply(lemmatize_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.198190Z","iopub.status.idle":"2023-07-31T02:22:05.198760Z","shell.execute_reply.started":"2023-07-31T02:22:05.198456Z","shell.execute_reply":"2023-07-31T02:22:05.198482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['lemmatized_complaints'].sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.200802Z","iopub.status.idle":"2023-07-31T02:22:05.201368Z","shell.execute_reply.started":"2023-07-31T02:22:05.201083Z","shell.execute_reply":"2023-07-31T02:22:05.201108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create a dataframe('df_clean') that will have only the complaints and the lemmatized complaints \ndf_clean = pd.DataFrame(columns=['complaint_what_happened','lemmatized_complaints'], data=df[['complaint_what_happened','lemmatized_complaints']])","metadata":{"id":"uXnN7aa_JrF0","execution":{"iopub.status.busy":"2023-07-31T02:22:05.202919Z","iopub.status.idle":"2023-07-31T02:22:05.203479Z","shell.execute_reply.started":"2023-07-31T02:22:05.203178Z","shell.execute_reply":"2023-07-31T02:22:05.203204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"nOiDVvEIJrF0","execution":{"iopub.status.busy":"2023-07-31T02:22:05.205229Z","iopub.status.idle":"2023-07-31T02:22:05.205808Z","shell.execute_reply.started":"2023-07-31T02:22:05.205489Z","shell.execute_reply":"2023-07-31T02:22:05.205517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Write your function to extract the POS tags\ndef extract_pos_tag(sentence):\n    # Tokenize the sentence into words\n    words = word_tokenize(sentence)\n    \n    # Perform POS tagging using nltk.pos_tag\n    pos_tags = nltk.pos_tag(words)\n    \n    # Extract words with tags 'NN', join them, and return\n    return ' '.join([word for (word, tag) in pos_tags if tag == \"NN\" and word != 'i'])\n\ndf_clean[\"complaint_POS_removed\"] = df_clean[\"lemmatized_complaints\"].progress_apply(extract_pos_tag)\ndf_clean[\"length\"] = df_clean[\"complaint_POS_removed\"].progress_apply(len)\n","metadata":{"id":"Kk7fc4DuJrF1","execution":{"iopub.status.busy":"2023-07-31T02:22:05.207500Z","iopub.status.idle":"2023-07-31T02:22:05.208092Z","shell.execute_reply.started":"2023-07-31T02:22:05.207774Z","shell.execute_reply":"2023-07-31T02:22:05.207800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The clean dataframe should now contain the raw complaint, lemmatized complaint and the complaint after removing POS tags.\ndf_clean","metadata":{"id":"AjxfchvFJrF2","execution":{"iopub.status.busy":"2023-07-31T02:22:05.209808Z","iopub.status.idle":"2023-07-31T02:22:05.210364Z","shell.execute_reply.started":"2023-07-31T02:22:05.210081Z","shell.execute_reply":"2023-07-31T02:22:05.210107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory data analysis to get familiar with the data.\n\nWrite the code in this task to perform the following:\n\n*   Visualise the data according to the 'Complaint' character length\n*   Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n*   Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text. ‘\n\n\n","metadata":{"id":"_7Un1AElJrF2"}},{"cell_type":"code","source":"# Write your code here to visualise the data according to the 'Complaint' character length\nplt.figure(figsize=(18,5))\nplt.hist([l for l in df_clean.length if l < 4000], bins=50)\nplt.xlabel(\"Complaint Character Length\")\nplt.show()","metadata":{"id":"q-zaqJF6JrF2","execution":{"iopub.status.busy":"2023-07-31T02:22:05.212379Z","iopub.status.idle":"2023-07-31T02:22:05.217366Z","shell.execute_reply.started":"2023-07-31T02:22:05.217079Z","shell.execute_reply":"2023-07-31T02:22:05.217113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Find the top 40 words by frequency among all the articles after processing the text.","metadata":{"id":"T9jD_6SeJrF3"}},{"cell_type":"code","source":"#Using a word cloud find the top 40 words by frequency among all the articles after processing the text\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(\n    max_words=40,\n    max_font_size=40\n).generate(str(df_clean['complaint_POS_removed']))\n\nfig = plt.figure(figsize=(20,15))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","metadata":{"id":"QcfdvtfZJrF3","execution":{"iopub.status.busy":"2023-07-31T02:22:05.218560Z","iopub.status.idle":"2023-07-31T02:22:05.218966Z","shell.execute_reply.started":"2023-07-31T02:22:05.218754Z","shell.execute_reply":"2023-07-31T02:22:05.218772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing -PRON- from the text corpus\ndf_clean['Complaint_clean'] = df_clean['complaint_POS_removed'].str.replace('-PRON-', '')","metadata":{"id":"OkSmc3UaJrF4","execution":{"iopub.status.busy":"2023-07-31T02:22:05.220832Z","iopub.status.idle":"2023-07-31T02:22:05.221251Z","shell.execute_reply.started":"2023-07-31T02:22:05.221055Z","shell.execute_reply":"2023-07-31T02:22:05.221074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text.","metadata":{"id":"5DfCSbbmJrF4"}},{"cell_type":"code","source":"#Write your code here to find the top 30 unigram frequency among the complaints in the cleaned datafram(df_clean). \ncomplaints_list = df_clean['Complaint_clean'].tolist()\n\n# Concatenate all complaints into a single string\nall_complaints_text = \" \".join(complaints_list)\n\n# Tokenize the text into words\nwords = word_tokenize(all_complaints_text)\n\n# Calculate the frequency distribution of unigrams\nfdist = FreqDist(words)\n\n# Get the top 30 most common unigrams\ntop_30_unigrams = fdist.most_common(30)\n\n# Create a DataFrame to display the results\ntop_30_unigrams_df = pd.DataFrame(top_30_unigrams, columns=['Unigram', 'Frequency'])\n\n# Display the top 30 unigrams\nprint(top_30_unigrams_df)","metadata":{"id":"5mbk5DS5JrF4","execution":{"iopub.status.busy":"2023-07-31T02:22:05.222830Z","iopub.status.idle":"2023-07-31T02:22:05.223242Z","shell.execute_reply.started":"2023-07-31T02:22:05.223052Z","shell.execute_reply":"2023-07-31T02:22:05.223070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the unigram frequency\ntop_30_unigrams_df.head(10)","metadata":{"id":"YX7fedm1JrF8","execution":{"iopub.status.busy":"2023-07-31T02:22:05.224797Z","iopub.status.idle":"2023-07-31T02:22:05.225197Z","shell.execute_reply.started":"2023-07-31T02:22:05.225008Z","shell.execute_reply":"2023-07-31T02:22:05.225027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your code here to find the top 30 bigram frequency among the complaints in the cleaned datafram(df_clean). \n# Create bigrams from the list of words\nbigrams = list(nltk.bigrams(words))\n\n# Calculate the frequency distribution of bigrams\nfdist = FreqDist(bigrams)\n\n# Get the top 30 most common bigrams\ntop_30_bigrams = fdist.most_common(30)\n\n# Create a DataFrame to display the results\ntop_30_bigrams_df = pd.DataFrame(top_30_bigrams, columns=['Bigram', 'Frequency'])\n\n# Display the top 30 bigrams\nprint(top_30_bigrams_df)","metadata":{"id":"aV7kD7w8JrF8","execution":{"iopub.status.busy":"2023-07-31T02:22:05.226762Z","iopub.status.idle":"2023-07-31T02:22:05.227497Z","shell.execute_reply.started":"2023-07-31T02:22:05.227289Z","shell.execute_reply":"2023-07-31T02:22:05.227310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the bigram frequency\ntop_30_bigrams_df.head(10)","metadata":{"id":"NPnMNIpyJrF9","execution":{"iopub.status.busy":"2023-07-31T02:22:05.228799Z","iopub.status.idle":"2023-07-31T02:22:05.229530Z","shell.execute_reply.started":"2023-07-31T02:22:05.229324Z","shell.execute_reply":"2023-07-31T02:22:05.229344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your code here to find the top 30 trigram frequency among the complaints in the cleaned datafram(df_clean). \n# Create trigrams from the list of words\ntrigrams = list(nltk.ngrams(words, 3))\n\n# Calculate the frequency distribution of trigrams\nfdist = FreqDist(trigrams)\n\n# Get the top 30 most common trigrams\ntop_30_trigrams = fdist.most_common(30)\n\n# Create a DataFrame to display the results\ntop_30_trigrams_df = pd.DataFrame(top_30_trigrams, columns=['Trigram', 'Frequency'])\n\n# Display the top 30 trigrams\nprint(top_30_trigrams_df)","metadata":{"id":"Xkh7vtbtJrF-","execution":{"iopub.status.busy":"2023-07-31T02:22:05.230802Z","iopub.status.idle":"2023-07-31T02:22:05.231262Z","shell.execute_reply.started":"2023-07-31T02:22:05.231058Z","shell.execute_reply":"2023-07-31T02:22:05.231078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the trigram frequency\ntop_30_trigrams_df.head(10)","metadata":{"id":"REcVxNfvJrF-","execution":{"iopub.status.busy":"2023-07-31T02:22:05.233083Z","iopub.status.idle":"2023-07-31T02:22:05.234192Z","shell.execute_reply.started":"2023-07-31T02:22:05.233954Z","shell.execute_reply":"2023-07-31T02:22:05.233985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The personal details of customer has been masked in the dataset with xxxx. Let's remove the masked text as this will be of no use for our analysis","metadata":{"id":"yUXzFji0JrF_"}},{"cell_type":"code","source":"df_clean['Complaint_clean'] = df_clean['Complaint_clean'].str.replace('xxxx','')","metadata":{"id":"wKda-a_IJrF_","execution":{"iopub.status.busy":"2023-07-31T02:22:05.235992Z","iopub.status.idle":"2023-07-31T02:22:05.236423Z","shell.execute_reply.started":"2023-07-31T02:22:05.236219Z","shell.execute_reply":"2023-07-31T02:22:05.236239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#All masked texts has been removed\ndf_clean","metadata":{"id":"9UIFk8fQJrF_","execution":{"iopub.status.busy":"2023-07-31T02:22:05.238625Z","iopub.status.idle":"2023-07-31T02:22:05.239436Z","shell.execute_reply.started":"2023-07-31T02:22:05.239220Z","shell.execute_reply":"2023-07-31T02:22:05.239242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction\nConvert the raw texts to a matrix of TF-IDF features\n\n**max_df** is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\"\nmax_df = 0.95 means \"ignore terms that appear in more than 95% of the complaints\"\n\n**min_df** is used for removing terms that appear too infrequently\nmin_df = 2 means \"ignore terms that appear in less than 2 complaints\"","metadata":{"id":"k-I0k0QtJrGA"}},{"cell_type":"code","source":"#Write your code here to initialise the TfidfVectorizer \ntfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words=\"english\")","metadata":{"id":"Y8fGwaCPJrGA","execution":{"iopub.status.busy":"2023-07-31T02:22:05.241016Z","iopub.status.idle":"2023-07-31T02:22:05.241444Z","shell.execute_reply.started":"2023-07-31T02:22:05.241242Z","shell.execute_reply":"2023-07-31T02:22:05.241261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create a document term matrix using fit_transform\n\nThe contents of a document term matrix are tuples of (complaint_id,token_id) tf-idf score:\nThe tuples that are not there have a tf-idf score of 0","metadata":{"id":"yYzD85nTJrGA"}},{"cell_type":"code","source":"#Write your code here to create the Document Term Matrix by transforming the complaints column present in df_clean.\ndtm = tfidf.fit_transform(df_clean.Complaint_clean)","metadata":{"id":"ffzdDpp_JrGB","execution":{"iopub.status.busy":"2023-07-31T02:22:05.243354Z","iopub.status.idle":"2023-07-31T02:22:05.243770Z","shell.execute_reply.started":"2023-07-31T02:22:05.243569Z","shell.execute_reply":"2023-07-31T02:22:05.243588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Topic Modelling using NMF\n\nNon-Negative Matrix Factorization (NMF) is an unsupervised technique so there are no labeling of topics that the model will be trained on. The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative.\n\nIn this task you have to perform the following:\n\n* Find the best number of clusters \n* Apply the best number to create word clusters\n* Inspect & validate the correction of each cluster wrt the complaints \n* Correct the labels if needed \n* Map the clusters to topics/cluster names","metadata":{"id":"7Q9lwvNEJrGB"}},{"cell_type":"code","source":"from sklearn.decomposition import NMF","metadata":{"id":"amLT4omWJrGB","execution":{"iopub.status.busy":"2023-07-31T02:22:05.244981Z","iopub.status.idle":"2023-07-31T02:22:05.245380Z","shell.execute_reply.started":"2023-07-31T02:22:05.245186Z","shell.execute_reply":"2023-07-31T02:22:05.245205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Manual Topic Modeling\nYou need to do take the trial & error approach to find the best num of topics for your NMF model.\n\nThe only parameter that is required is the number of components i.e. the number of topics we want. This is the most crucial step in the whole topic modeling process and will greatly affect how good your final topics are.","metadata":{"id":"0wYR1xUTJrGD"}},{"cell_type":"code","source":"#Load your nmf_model with the n_components i.e 5\nnum_topics = 5 #write the value you want to test out\n\n#keep the random_state =40\nnmf_model = NMF(n_components=num_topics, random_state=40) #write your code here","metadata":{"id":"sgd2A6bhJrGD","execution":{"iopub.status.busy":"2023-07-31T02:22:05.247462Z","iopub.status.idle":"2023-07-31T02:22:05.247903Z","shell.execute_reply.started":"2023-07-31T02:22:05.247672Z","shell.execute_reply":"2023-07-31T02:22:05.247692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nmf_model.fit(dtm)\nlen(tfidf.get_feature_names_out())","metadata":{"id":"VPMDYbt_JrGE","execution":{"iopub.status.busy":"2023-07-31T02:22:05.249321Z","iopub.status.idle":"2023-07-31T02:22:05.250156Z","shell.execute_reply.started":"2023-07-31T02:22:05.249932Z","shell.execute_reply":"2023-07-31T02:22:05.249954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the Top15 words for each of the topics\nfor index,topic in enumerate(nmf_model.components_):\n    words_in_topic = []\n    for word_index in topic.argsort()[-15:]:\n        words_in_topic.append(tfidf.get_feature_names_out()[word_index])\n    print(f'topic {index + 1}: {words_in_topic}')\n    print('\\n')","metadata":{"id":"16kRfat5JrGE","execution":{"iopub.status.busy":"2023-07-31T02:22:05.252292Z","iopub.status.idle":"2023-07-31T02:22:05.252725Z","shell.execute_reply.started":"2023-07-31T02:22:05.252525Z","shell.execute_reply":"2023-07-31T02:22:05.252545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create the best topic for each complaint in terms of integer value 0,1,2,3 & 4\ntopic_results = nmf_model.transform(dtm)\ntopic_results[0].round(2)\ntopic_results[0].argmax()\ntopic_results.argmax(axis=1)","metadata":{"id":"0OIT7LmFJrGF","execution":{"iopub.status.busy":"2023-07-31T02:22:05.254034Z","iopub.status.idle":"2023-07-31T02:22:05.254440Z","shell.execute_reply.started":"2023-07-31T02:22:05.254242Z","shell.execute_reply":"2023-07-31T02:22:05.254261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assign the best topic to each of the cmplaints in Topic Column\n\ndf_clean['Topic'] = df_clean['Topic'] = topic_results.argmax(axis = 1) #write your code to assign topics to each rows.","metadata":{"id":"peyYv-ORJrGF","execution":{"iopub.status.busy":"2023-07-31T02:22:05.255985Z","iopub.status.idle":"2023-07-31T02:22:05.256415Z","shell.execute_reply.started":"2023-07-31T02:22:05.256214Z","shell.execute_reply":"2023-07-31T02:22:05.256234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean.head()","metadata":{"id":"fLh_Gf3nJrGF","execution":{"iopub.status.busy":"2023-07-31T02:22:05.257906Z","iopub.status.idle":"2023-07-31T02:22:05.258367Z","shell.execute_reply.started":"2023-07-31T02:22:05.258121Z","shell.execute_reply":"2023-07-31T02:22:05.258140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the first 5 Complaint for each of the Topics\ndf_clean=df_clean.groupby('Topic').head(5)\ndf_clean.sort_values('Topic')","metadata":{"id":"aQKpufSPJrGG","execution":{"iopub.status.busy":"2023-07-31T02:22:05.261075Z","iopub.status.idle":"2023-07-31T02:22:05.261510Z","shell.execute_reply.started":"2023-07-31T02:22:05.261300Z","shell.execute_reply":"2023-07-31T02:22:05.261320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### After evaluating the mapping, if the topics assigned are correct then assign these names to the relevant topic:\n* Bank Account services\n* Credit card or prepaid card\n* Theft/Dispute Reporting\n* Mortgage/Loan\n* Others","metadata":{"id":"piyLxzj6v07j"}},{"cell_type":"code","source":"#Create the dictionary of Topic names and Topics\n\nTopic_names = {0:\"Bank Account services\",\n               1:\"Credit card or prepaid card\", \n               2:\"Others\",\n               3:\"Theft/Dispute Reporting\",\n               4:\"Mortgage/Loan\"}\n#Replace Topics with Topic Names\ndf_clean['Topic'] = df_clean['Topic'].map(Topic_names)","metadata":{"id":"TWpwDG4RJrGG","execution":{"iopub.status.busy":"2023-07-31T02:22:05.263350Z","iopub.status.idle":"2023-07-31T02:22:05.263774Z","shell.execute_reply.started":"2023-07-31T02:22:05.263572Z","shell.execute_reply":"2023-07-31T02:22:05.263592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"-2ULY5K6JrGG","execution":{"iopub.status.busy":"2023-07-31T02:22:05.265689Z","iopub.status.idle":"2023-07-31T02:22:05.266467Z","shell.execute_reply.started":"2023-07-31T02:22:05.266254Z","shell.execute_reply":"2023-07-31T02:22:05.266276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supervised model to predict any new complaints to the relevant Topics.\n\nYou have now build the model to create the topics for each complaints.Now in the below section you will use them to classify any new complaints.\n\nSince you will be using supervised learning technique we have to convert the topic names to numbers(numpy arrays only understand numbers)","metadata":{"id":"7Mu0QBOcJrGH"}},{"cell_type":"code","source":"#Create the dictionary again of Topic names and Topics\n\nTopic_names = {\"Bank Account services\":0,\n               \"Credit card or prepaid card\":1,\n               \"Others\":2,\n               \"Theft/Dispute Reporting\":3,\n               \"Mortgage/Loan\":4}\n#Replace Topics with Topic Names\ndf_clean['Topic'] = df_clean['Topic'].map(Topic_names)","metadata":{"id":"_U8J3J8wJrGH","execution":{"iopub.status.busy":"2023-07-31T02:22:05.268812Z","iopub.status.idle":"2023-07-31T02:22:05.269269Z","shell.execute_reply.started":"2023-07-31T02:22:05.269066Z","shell.execute_reply":"2023-07-31T02:22:05.269087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"BWIgJUkQJrGH","execution":{"iopub.status.busy":"2023-07-31T02:22:05.270953Z","iopub.status.idle":"2023-07-31T02:22:05.271364Z","shell.execute_reply.started":"2023-07-31T02:22:05.271165Z","shell.execute_reply":"2023-07-31T02:22:05.271184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Keep the columns\"complaint_what_happened\" & \"Topic\" only in the new dataframe --> training_data\ntraining_data = df_clean[[\"complaint_what_happened\",\"Topic\"]]","metadata":{"id":"Xx-FrbkWJrGH","execution":{"iopub.status.busy":"2023-07-31T02:22:05.273101Z","iopub.status.idle":"2023-07-31T02:22:05.273534Z","shell.execute_reply.started":"2023-07-31T02:22:05.273325Z","shell.execute_reply":"2023-07-31T02:22:05.273344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data","metadata":{"id":"lVg2pa12JrGI","execution":{"iopub.status.busy":"2023-07-31T02:22:05.275492Z","iopub.status.idle":"2023-07-31T02:22:05.275935Z","shell.execute_reply.started":"2023-07-31T02:22:05.275705Z","shell.execute_reply":"2023-07-31T02:22:05.275725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####Apply the supervised models on the training data created. In this process, you have to do the following:\n* Create the vector counts using Count Vectoriser\n* Transform the word vecotr to tf-idf\n* Create the train & test data using the train_test_split on the tf-idf & topics\n","metadata":{"id":"280Vbqk-7a8M"}},{"cell_type":"code","source":"\n#Write your code to get the Vector count\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(training_data.complaintwhathappened)\n\n#Write your code here to transform the word vector to tf-idf\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)","metadata":{"id":"oUlQpgkzJrGI","execution":{"iopub.status.busy":"2023-07-31T02:22:05.277372Z","iopub.status.idle":"2023-07-31T02:22:05.278167Z","shell.execute_reply.started":"2023-07-31T02:22:05.277906Z","shell.execute_reply":"2023-07-31T02:22:05.277938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Performing Train-Test split\nX_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, training_data.Topic, test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.279527Z","iopub.status.idle":"2023-07-31T02:22:05.279965Z","shell.execute_reply.started":"2023-07-31T02:22:05.279734Z","shell.execute_reply":"2023-07-31T02:22:05.279753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You have to try atleast 3 models on the train & test data from these options:\n* Logistic regression\n* Decision Tree\n* Random Forest\n* Naive Bayes (optional)\n\n**Using the required evaluation metrics judge the tried models and select the ones performing the best**","metadata":{"id":"uMU3vj6w-wqL"}},{"cell_type":"code","source":"# Write your code here to build any 3 models and evaluate them using the required metrics\n\n\n\n","metadata":{"id":"udLHpPsZJrGI","execution":{"iopub.status.busy":"2023-07-31T02:22:05.282158Z","iopub.status.idle":"2023-07-31T02:22:05.282942Z","shell.execute_reply.started":"2023-07-31T02:22:05.282697Z","shell.execute_reply":"2023-07-31T02:22:05.282719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\n\n# Run the Logistic Regression model\nmodel_name = 'LOGISTIC REGRESSION'\nclf_lr = LogisticRegression(solver='liblinear')\nclf_lr.fit(X_train, y_train)\ny_pred_lr = clf_lr.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.285059Z","iopub.status.idle":"2023-07-31T02:22:05.286041Z","shell.execute_reply.started":"2023-07-31T02:22:05.285754Z","shell.execute_reply":"2023-07-31T02:22:05.285777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate F1 Score using weighted average method\nf1_lr = f1_score(y_test, y_pred_lr, average=\"weighted\")\nf1_lr","metadata":{"id":"N2OznsObJrGP","execution":{"iopub.status.busy":"2023-07-31T02:22:05.287712Z","iopub.status.idle":"2023-07-31T02:22:05.288498Z","shell.execute_reply.started":"2023-07-31T02:22:05.288282Z","shell.execute_reply":"2023-07-31T02:22:05.288305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Run Decision Tree on default hyperparameters\nmodel_name = 'DECISION TREE'\nclf_dt = DecisionTreeClassifier()\n%time \nclf_dt.fit(X_train, y_train)\ny_pred_dt = clf_dt.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.290073Z","iopub.status.idle":"2023-07-31T02:22:05.290494Z","shell.execute_reply.started":"2023-07-31T02:22:05.290295Z","shell.execute_reply":"2023-07-31T02:22:05.290314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate F1 Score using weighted average method\nf1_dt = f1_score(y_test, y_pred_dt, average=\"weighted\")\nf1_dt","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.291779Z","iopub.status.idle":"2023-07-31T02:22:05.292229Z","shell.execute_reply.started":"2023-07-31T02:22:05.292029Z","shell.execute_reply":"2023-07-31T02:22:05.292049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Run the Random Forest model on default hyperparameters\nmodel_name = 'RANDOM FOREST'\nclf_rf = RandomForestClassifier()\n%time \nclf_rf.fit(X_train, y_train)\ny_pred_rf = clf_rf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.294419Z","iopub.status.idle":"2023-07-31T02:22:05.294847Z","shell.execute_reply.started":"2023-07-31T02:22:05.294647Z","shell.execute_reply":"2023-07-31T02:22:05.294667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate F1 Score using weighted average method\nf1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\nf1_rf","metadata":{"execution":{"iopub.status.busy":"2023-07-31T02:22:05.296573Z","iopub.status.idle":"2023-07-31T02:22:05.297024Z","shell.execute_reply.started":"2023-07-31T02:22:05.296785Z","shell.execute_reply":"2023-07-31T02:22:05.296804Z"},"trusted":true},"execution_count":null,"outputs":[]}]}