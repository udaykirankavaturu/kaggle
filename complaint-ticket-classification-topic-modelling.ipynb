{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem Statement \n\nYou need to build a model that is able to classify customer complaints based on the products/services. By doing so, you can segregate these tickets into their relevant categories and, therefore, help in the quick resolution of the issue.\n\nYou will be doing topic modelling on the <b>.json</b> data provided by the company. Since this data is not labelled, you need to apply NMF to analyse patterns and classify tickets into the following five clusters based on their products/services:\n\n* Credit card / Prepaid card\n\n* Bank account services\n\n* Theft/Dispute reporting\n\n* Mortgages/loans\n\n* Others \n\n\nWith the help of topic modelling, you will be able to map each ticket onto its respective department/category. You can then use this data to train any supervised model such as logistic regression, decision tree or random forest. Using this trained model, you can classify any new customer complaint support ticket into its relevant department.","metadata":{"id":"rhR-ZUkwJrFn"}},{"cell_type":"markdown","source":"## Pipelines that needs to be performed:\n\nYou need to perform the following eight major tasks to complete the assignment:\n\n1.  Data loading\n\n2. Text preprocessing\n\n3. Exploratory data analysis (EDA)\n\n4. Feature extraction\n\n5. Topic modelling \n\n6. Model building using supervised learning\n\n7. Model training and evaluation\n\n8. Model inference","metadata":{"id":"mcgXVNyaLUFS"}},{"cell_type":"markdown","source":"## Importing the necessary libraries","metadata":{"id":"JuLFIymAL58u"}},{"cell_type":"code","source":"import json \nimport numpy as np\nimport pandas as pd\nimport re, nltk, spacy, string\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom plotly.offline import plot\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom pprint import pprint\n\nfrom nltk.corpus import wordnet\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer","metadata":{"id":"O-Q9pqrcJrFr","execution":{"iopub.status.busy":"2023-07-27T04:18:29.720554Z","iopub.execute_input":"2023-07-27T04:18:29.721061Z","iopub.status.idle":"2023-07-27T04:18:45.843713Z","shell.execute_reply.started":"2023-07-27T04:18:29.721029Z","shell.execute_reply":"2023-07-27T04:18:45.842438Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:45.846424Z","iopub.execute_input":"2023-07-27T04:18:45.846862Z","iopub.status.idle":"2023-07-27T04:18:46.075614Z","shell.execute_reply.started":"2023-07-27T04:18:45.846822Z","shell.execute_reply":"2023-07-27T04:18:46.074555Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:46.077239Z","iopub.execute_input":"2023-07-27T04:18:46.077557Z","iopub.status.idle":"2023-07-27T04:18:47.538775Z","shell.execute_reply.started":"2023-07-27T04:18:46.077529Z","shell.execute_reply":"2023-07-27T04:18:47.537479Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading the data\n\nThe data is in JSON format and we need to convert it to a dataframe.","metadata":{"id":"KtRLCsNVJrFt"}},{"cell_type":"code","source":"# Opening JSON file \nf = open('/kaggle/input/automatic-ticket-classification/complaints-2021-05-14_08_16.json')# Write the path to your data file and load it \n  \n# returns JSON object as  \n# a dictionary \ndata = json.load(f)\ndf=pd.json_normalize(data)","metadata":{"id":"puVzIf_iJrFt","execution":{"iopub.status.busy":"2023-07-27T04:18:47.540816Z","iopub.execute_input":"2023-07-27T04:18:47.541149Z","iopub.status.idle":"2023-07-27T04:18:52.768503Z","shell.execute_reply.started":"2023-07-27T04:18:47.541116Z","shell.execute_reply":"2023-07-27T04:18:52.767378Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation","metadata":{"id":"_xYpH-sAJrFu"}},{"cell_type":"code","source":"# Inspect the dataframe to understand the given data.\ndf.sample(10)\n","metadata":{"id":"Lf8ufHH5JrFu","execution":{"iopub.status.busy":"2023-07-27T04:18:52.771455Z","iopub.execute_input":"2023-07-27T04:18:52.771791Z","iopub.status.idle":"2023-07-27T04:18:52.816330Z","shell.execute_reply.started":"2023-07-27T04:18:52.771762Z","shell.execute_reply":"2023-07-27T04:18:52.815091Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                    _index      _type      _id  _score   _source.tags  \\\n57446  complaint-public-v2  complaint  2600747     0.0           None   \n2989   complaint-public-v2  complaint    29845     0.0           None   \n59682  complaint-public-v2  complaint   491740     0.0           None   \n13187  complaint-public-v2  complaint  1697069     0.0           None   \n63897  complaint-public-v2  complaint    30642     0.0           None   \n10628  complaint-public-v2  complaint  3518424     0.0           None   \n61120  complaint-public-v2  complaint   977060     0.0           None   \n542    complaint-public-v2  complaint  3448018     0.0           None   \n15949  complaint-public-v2  complaint  2657515     0.0           None   \n6709   complaint-public-v2  complaint  4272966     0.0  Servicemember   \n\n      _source.zip_code _source.complaint_id  \\\n57446            900XX              2600747   \n2989             75126                29845   \n59682            902XX               491740   \n13187            31210              1697069   \n63897            073XX                30642   \n10628            088XX              3518424   \n61120            28104               977060   \n542               None              3448018   \n15949             None              2657515   \n6709             953XX              4272966   \n\n                                           _source.issue  \\\n57446                              Closing on a mortgage   \n2989            Loan servicing, payments, escrow account   \n59682           Loan servicing, payments, escrow account   \n13187            Account opening, closing, or management   \n63897                               Credit determination   \n10628                     Trouble during payment process   \n61120           Loan modification,collection,foreclosure   \n542    Problem with a company's investigation into an...   \n15949                 Other features, terms, or problems   \n6709     Problem with a purchase shown on your statement   \n\n           _source.date_received _source.state  ...  \\\n57446  2017-08-10T12:00:00-05:00            CA  ...   \n2989   2012-03-04T12:00:00-05:00            TX  ...   \n59682  2013-08-13T12:00:00-05:00            CA  ...   \n13187  2015-12-15T12:00:00-05:00            GA  ...   \n63897  2012-03-06T12:00:00-05:00            NJ  ...   \n10628  2020-01-31T12:00:00-05:00            NJ  ...   \n61120  2014-08-10T12:00:00-05:00            NC  ...   \n542    2019-11-23T12:00:00-05:00            TX  ...   \n15949  2017-09-03T12:00:00-05:00            MA  ...   \n6709   2021-04-05T12:00:00-05:00            CA  ...   \n\n          _source.company_response       _source.company  \\\n57446      Closed with explanation  JPMORGAN CHASE & CO.   \n2989         Closed without relief  JPMORGAN CHASE & CO.   \n59682                       Closed  JPMORGAN CHASE & CO.   \n13187      Closed with explanation  JPMORGAN CHASE & CO.   \n63897           Closed with relief  JPMORGAN CHASE & CO.   \n10628      Closed with explanation  JPMORGAN CHASE & CO.   \n61120      Closed with explanation  JPMORGAN CHASE & CO.   \n542        Closed with explanation  JPMORGAN CHASE & CO.   \n15949      Closed with explanation  JPMORGAN CHASE & CO.   \n6709   Closed with monetary relief  JPMORGAN CHASE & CO.   \n\n      _source.submitted_via _source.date_sent_to_company  \\\n57446                   Web    2017-08-10T12:00:00-05:00   \n2989                    Web    2012-03-05T12:00:00-05:00   \n59682              Referral    2013-08-14T12:00:00-05:00   \n13187              Referral    2015-12-16T12:00:00-05:00   \n63897                   Web    2012-03-06T12:00:00-05:00   \n10628              Referral    2020-02-05T12:00:00-05:00   \n61120                   Web    2014-08-13T12:00:00-05:00   \n542                     Web    2019-11-23T12:00:00-05:00   \n15949                   Web    2017-09-03T12:00:00-05:00   \n6709                    Web    2021-04-05T12:00:00-05:00   \n\n      _source.company_public_response  \\\n57446                            None   \n2989                             None   \n59682                            None   \n13187                            None   \n63897                            None   \n10628                            None   \n61120                            None   \n542                              None   \n15949                            None   \n6709                             None   \n\n                              _source.sub_product _source.timely  \\\n57446                  Conventional home mortgage            Yes   \n2989                  Conventional fixed mortgage            Yes   \n59682                              Other mortgage            Yes   \n13187                            Checking account            Yes   \n63897                                        None            Yes   \n10628                      Other type of mortgage            Yes   \n61120                 Conventional fixed mortgage            Yes   \n542                Other personal consumer report            Yes   \n15949                           Store credit card            Yes   \n6709   General-purpose credit card or charge card            Yes   \n\n                         _source.complaint_what_happened  \\\n57446                                                      \n2989                                                       \n59682                                                      \n13187                                                      \n63897                                                      \n10628                                                      \n61120                                                      \n542    On XX/XX/2019, I walked inside the JP Morgan C...   \n15949  I applied for an Amazon credit card ( Chase Ba...   \n6709                                                       \n\n                                       _source.sub_issue  \\\n57446                                               None   \n2989                                                None   \n59682                                               None   \n13187                                               None   \n63897                                               None   \n10628                                               None   \n61120                                               None   \n542           Problem with personal statement of dispute   \n15949                                      Other problem   \n6709   Credit card company isn't resolving a dispute ...   \n\n      _source.consumer_consent_provided  \n57446              Consent not provided  \n2989                                N/A  \n59682                               N/A  \n13187                               N/A  \n63897                               N/A  \n10628                               N/A  \n61120                               N/A  \n542                    Consent provided  \n15949                  Consent provided  \n6709                               None  \n\n[10 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_index</th>\n      <th>_type</th>\n      <th>_id</th>\n      <th>_score</th>\n      <th>_source.tags</th>\n      <th>_source.zip_code</th>\n      <th>_source.complaint_id</th>\n      <th>_source.issue</th>\n      <th>_source.date_received</th>\n      <th>_source.state</th>\n      <th>...</th>\n      <th>_source.company_response</th>\n      <th>_source.company</th>\n      <th>_source.submitted_via</th>\n      <th>_source.date_sent_to_company</th>\n      <th>_source.company_public_response</th>\n      <th>_source.sub_product</th>\n      <th>_source.timely</th>\n      <th>_source.complaint_what_happened</th>\n      <th>_source.sub_issue</th>\n      <th>_source.consumer_consent_provided</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57446</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2600747</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>900XX</td>\n      <td>2600747</td>\n      <td>Closing on a mortgage</td>\n      <td>2017-08-10T12:00:00-05:00</td>\n      <td>CA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2017-08-10T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Conventional home mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>Consent not provided</td>\n    </tr>\n    <tr>\n      <th>2989</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>29845</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>75126</td>\n      <td>29845</td>\n      <td>Loan servicing, payments, escrow account</td>\n      <td>2012-03-04T12:00:00-05:00</td>\n      <td>TX</td>\n      <td>...</td>\n      <td>Closed without relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2012-03-05T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Conventional fixed mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>59682</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>491740</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>902XX</td>\n      <td>491740</td>\n      <td>Loan servicing, payments, escrow account</td>\n      <td>2013-08-13T12:00:00-05:00</td>\n      <td>CA</td>\n      <td>...</td>\n      <td>Closed</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2013-08-14T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>13187</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>1697069</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>31210</td>\n      <td>1697069</td>\n      <td>Account opening, closing, or management</td>\n      <td>2015-12-15T12:00:00-05:00</td>\n      <td>GA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2015-12-16T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>63897</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>30642</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>073XX</td>\n      <td>30642</td>\n      <td>Credit determination</td>\n      <td>2012-03-06T12:00:00-05:00</td>\n      <td>NJ</td>\n      <td>...</td>\n      <td>Closed with relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2012-03-06T12:00:00-05:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>10628</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3518424</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>088XX</td>\n      <td>3518424</td>\n      <td>Trouble during payment process</td>\n      <td>2020-01-31T12:00:00-05:00</td>\n      <td>NJ</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2020-02-05T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other type of mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>61120</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>977060</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>28104</td>\n      <td>977060</td>\n      <td>Loan modification,collection,foreclosure</td>\n      <td>2014-08-10T12:00:00-05:00</td>\n      <td>NC</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2014-08-13T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Conventional fixed mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>542</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3448018</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>3448018</td>\n      <td>Problem with a company's investigation into an...</td>\n      <td>2019-11-23T12:00:00-05:00</td>\n      <td>TX</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2019-11-23T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other personal consumer report</td>\n      <td>Yes</td>\n      <td>On XX/XX/2019, I walked inside the JP Morgan C...</td>\n      <td>Problem with personal statement of dispute</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>15949</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2657515</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2657515</td>\n      <td>Other features, terms, or problems</td>\n      <td>2017-09-03T12:00:00-05:00</td>\n      <td>MA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2017-09-03T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Store credit card</td>\n      <td>Yes</td>\n      <td>I applied for an Amazon credit card ( Chase Ba...</td>\n      <td>Other problem</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>6709</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>4272966</td>\n      <td>0.0</td>\n      <td>Servicemember</td>\n      <td>953XX</td>\n      <td>4272966</td>\n      <td>Problem with a purchase shown on your statement</td>\n      <td>2021-04-05T12:00:00-05:00</td>\n      <td>CA</td>\n      <td>...</td>\n      <td>Closed with monetary relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2021-04-05T12:00:00-05:00</td>\n      <td>None</td>\n      <td>General-purpose credit card or charge card</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Credit card company isn't resolving a dispute ...</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:52.818546Z","iopub.execute_input":"2023-07-27T04:18:52.819005Z","iopub.status.idle":"2023-07-27T04:18:52.825221Z","shell.execute_reply.started":"2023-07-27T04:18:52.818963Z","shell.execute_reply":"2023-07-27T04:18:52.824465Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(78313, 22)"},"metadata":{}}]},{"cell_type":"code","source":"#print the column names\ndf.columns","metadata":{"id":"Dwcty-wmJrFw","execution":{"iopub.status.busy":"2023-07-27T04:18:52.826737Z","iopub.execute_input":"2023-07-27T04:18:52.827320Z","iopub.status.idle":"2023-07-27T04:18:52.839939Z","shell.execute_reply.started":"2023-07-27T04:18:52.827290Z","shell.execute_reply":"2023-07-27T04:18:52.838968Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Index(['_index', '_type', '_id', '_score', '_source.tags', '_source.zip_code',\n       '_source.complaint_id', '_source.issue', '_source.date_received',\n       '_source.state', '_source.consumer_disputed', '_source.product',\n       '_source.company_response', '_source.company', '_source.submitted_via',\n       '_source.date_sent_to_company', '_source.company_public_response',\n       '_source.sub_product', '_source.timely',\n       '_source.complaint_what_happened', '_source.sub_issue',\n       '_source.consumer_consent_provided'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"#Assign new column names\nfor column in df.columns:\n    new_column = column.replace(\"_\",\"\").replace(\"source.\", \"\")\n    df.rename(columns={column: new_column}, inplace=True)","metadata":{"id":"FYCtKXD1JrFw","execution":{"iopub.status.busy":"2023-07-27T04:18:52.841136Z","iopub.execute_input":"2023-07-27T04:18:52.841411Z","iopub.status.idle":"2023-07-27T04:18:52.862403Z","shell.execute_reply.started":"2023-07-27T04:18:52.841386Z","shell.execute_reply":"2023-07-27T04:18:52.861261Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:52.863577Z","iopub.execute_input":"2023-07-27T04:18:52.864473Z","iopub.status.idle":"2023-07-27T04:18:52.870441Z","shell.execute_reply.started":"2023-07-27T04:18:52.864443Z","shell.execute_reply":"2023-07-27T04:18:52.869624Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['index', 'type', 'id', 'score', 'tags', 'zipcode', 'complaintid',\n       'issue', 'datereceived', 'state', 'consumerdisputed', 'product',\n       'companyresponse', 'company', 'submittedvia', 'datesenttocompany',\n       'companypublicresponse', 'subproduct', 'timely',\n       'complaintwhathappened', 'subissue', 'consumerconsentprovided'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:52.871680Z","iopub.execute_input":"2023-07-27T04:18:52.872767Z","iopub.status.idle":"2023-07-27T04:18:52.906061Z","shell.execute_reply.started":"2023-07-27T04:18:52.872738Z","shell.execute_reply":"2023-07-27T04:18:52.904997Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                     index       type       id  score  tags zipcode  \\\n63989  complaint-public-v2  complaint   103595    0.0  None   10977   \n5196   complaint-public-v2  complaint  3673348    0.0  None   301XX   \n22909  complaint-public-v2  complaint  2851123    0.0  None    None   \n36268  complaint-public-v2  complaint   101281    0.0  None   20876   \n61477  complaint-public-v2  complaint  2124349    0.0  None   945XX   \n47945  complaint-public-v2  complaint  2925053    0.0  None   347XX   \n54661  complaint-public-v2  complaint  1565552    0.0  None    None   \n2582   complaint-public-v2  complaint   587025    0.0  None   088XX   \n26875  complaint-public-v2  complaint  4246327    0.0  None   850XX   \n54478  complaint-public-v2  complaint  1344584    0.0  None    None   \n\n      complaintid                                            issue  \\\n63989      103595         Loan modification,collection,foreclosure   \n5196      3673348                      Improper use of your report   \n22909     2851123  Problem with a purchase shown on your statement   \n36268      101281         Loan servicing, payments, escrow account   \n61477     2124349                                 Billing disputes   \n47945     2925053                              Managing an account   \n54661     1565552         Loan servicing, payments, escrow account   \n2582       587025          Account opening, closing, or management   \n26875     4246327                              Managing an account   \n54478     1344584                    Credit line increase/decrease   \n\n                    datereceived state  ...                  companyresponse  \\\n63989  2012-06-18T12:00:00-05:00    NY  ...          Closed with explanation   \n5196   2020-05-29T12:00:00-05:00    GA  ...          Closed with explanation   \n22909  2018-03-22T12:00:00-05:00  None  ...          Closed with explanation   \n36268  2012-06-13T12:00:00-05:00    MD  ...                           Closed   \n61477  2016-09-21T12:00:00-05:00    CA  ...          Closed with explanation   \n47945  2018-06-03T12:00:00-05:00    FL  ...          Closed with explanation   \n54661  2015-09-15T12:00:00-05:00    MN  ...          Closed with explanation   \n2582   2013-11-05T12:00:00-05:00    NJ  ...      Closed with monetary relief   \n26875  2021-03-25T12:00:00-05:00    AZ  ...          Closed with explanation   \n54478  2015-04-23T12:00:00-05:00    CO  ...  Closed with non-monetary relief   \n\n                    company submittedvia          datesenttocompany  \\\n63989  JPMORGAN CHASE & CO.     Referral  2012-06-25T12:00:00-05:00   \n5196   JPMORGAN CHASE & CO.          Web  2020-05-29T12:00:00-05:00   \n22909  JPMORGAN CHASE & CO.  Postal mail  2018-03-22T12:00:00-05:00   \n36268  JPMORGAN CHASE & CO.     Referral  2012-06-18T12:00:00-05:00   \n61477  JPMORGAN CHASE & CO.          Web  2016-09-21T12:00:00-05:00   \n47945  JPMORGAN CHASE & CO.          Web  2018-06-03T12:00:00-05:00   \n54661  JPMORGAN CHASE & CO.          Web  2015-09-15T12:00:00-05:00   \n2582   JPMORGAN CHASE & CO.     Referral  2013-11-07T12:00:00-05:00   \n26875  JPMORGAN CHASE & CO.          Web  2021-03-26T12:00:00-05:00   \n54478  JPMORGAN CHASE & CO.          Web  2015-04-23T12:00:00-05:00   \n\n      companypublicresponse                                  subproduct  \\\n63989                  None                              Other mortgage   \n5196                   None                            Credit reporting   \n22909                  None  General-purpose credit card or charge card   \n36268                  None                              Other mortgage   \n61477                  None                                        None   \n47945                  None                            Checking account   \n54661                  None      Conventional adjustable mortgage (ARM)   \n2582                   None                            Checking account   \n26875                  None                            Checking account   \n54478                  None                                        None   \n\n      timely                              complaintwhathappened  \\\n63989    Yes                                                      \n5196     Yes  on XX/XX/XXXX I recived a inquiry on my credit...   \n22909    Yes                                                      \n36268    Yes                                                      \n61477    Yes  I went to XXXX XXXX XX/XX/XXXX-XX/XX/2016 stay...   \n47945    Yes  I had a transaction posted to my account on XX...   \n54661    Yes  XX/XX/XXXX I received a notice from Chase that...   \n2582     Yes                                                      \n26875    Yes                                                      \n54478    Yes  I have had several cards in good standing with...   \n\n                                                subissue  \\\n63989                                               None   \n5196   Credit inquiries on your report that you don't...   \n22909  Credit card company isn't resolving a dispute ...   \n36268                                               None   \n61477                                               None   \n47945                                        Fee problem   \n54661                                               None   \n2582                                                None   \n26875                           Deposits and withdrawals   \n54478                                               None   \n\n      consumerconsentprovided  \n63989                     N/A  \n5196         Consent provided  \n22909                     N/A  \n36268                     N/A  \n61477        Consent provided  \n47945        Consent provided  \n54661        Consent provided  \n2582                      N/A  \n26875                    None  \n54478        Consent provided  \n\n[10 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>type</th>\n      <th>id</th>\n      <th>score</th>\n      <th>tags</th>\n      <th>zipcode</th>\n      <th>complaintid</th>\n      <th>issue</th>\n      <th>datereceived</th>\n      <th>state</th>\n      <th>...</th>\n      <th>companyresponse</th>\n      <th>company</th>\n      <th>submittedvia</th>\n      <th>datesenttocompany</th>\n      <th>companypublicresponse</th>\n      <th>subproduct</th>\n      <th>timely</th>\n      <th>complaintwhathappened</th>\n      <th>subissue</th>\n      <th>consumerconsentprovided</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>63989</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>103595</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>10977</td>\n      <td>103595</td>\n      <td>Loan modification,collection,foreclosure</td>\n      <td>2012-06-18T12:00:00-05:00</td>\n      <td>NY</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2012-06-25T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>5196</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>3673348</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>301XX</td>\n      <td>3673348</td>\n      <td>Improper use of your report</td>\n      <td>2020-05-29T12:00:00-05:00</td>\n      <td>GA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2020-05-29T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Credit reporting</td>\n      <td>Yes</td>\n      <td>on XX/XX/XXXX I recived a inquiry on my credit...</td>\n      <td>Credit inquiries on your report that you don't...</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>22909</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2851123</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2851123</td>\n      <td>Problem with a purchase shown on your statement</td>\n      <td>2018-03-22T12:00:00-05:00</td>\n      <td>None</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Postal mail</td>\n      <td>2018-03-22T12:00:00-05:00</td>\n      <td>None</td>\n      <td>General-purpose credit card or charge card</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Credit card company isn't resolving a dispute ...</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>36268</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>101281</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>20876</td>\n      <td>101281</td>\n      <td>Loan servicing, payments, escrow account</td>\n      <td>2012-06-13T12:00:00-05:00</td>\n      <td>MD</td>\n      <td>...</td>\n      <td>Closed</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2012-06-18T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Other mortgage</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>61477</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2124349</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>945XX</td>\n      <td>2124349</td>\n      <td>Billing disputes</td>\n      <td>2016-09-21T12:00:00-05:00</td>\n      <td>CA</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2016-09-21T12:00:00-05:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Yes</td>\n      <td>I went to XXXX XXXX XX/XX/XXXX-XX/XX/2016 stay...</td>\n      <td>None</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>47945</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>2925053</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>347XX</td>\n      <td>2925053</td>\n      <td>Managing an account</td>\n      <td>2018-06-03T12:00:00-05:00</td>\n      <td>FL</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2018-06-03T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td>I had a transaction posted to my account on XX...</td>\n      <td>Fee problem</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>54661</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>1565552</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1565552</td>\n      <td>Loan servicing, payments, escrow account</td>\n      <td>2015-09-15T12:00:00-05:00</td>\n      <td>MN</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2015-09-15T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Conventional adjustable mortgage (ARM)</td>\n      <td>Yes</td>\n      <td>XX/XX/XXXX I received a notice from Chase that...</td>\n      <td>None</td>\n      <td>Consent provided</td>\n    </tr>\n    <tr>\n      <th>2582</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>587025</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>088XX</td>\n      <td>587025</td>\n      <td>Account opening, closing, or management</td>\n      <td>2013-11-05T12:00:00-05:00</td>\n      <td>NJ</td>\n      <td>...</td>\n      <td>Closed with monetary relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Referral</td>\n      <td>2013-11-07T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td></td>\n      <td>None</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>26875</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>4246327</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>850XX</td>\n      <td>4246327</td>\n      <td>Managing an account</td>\n      <td>2021-03-25T12:00:00-05:00</td>\n      <td>AZ</td>\n      <td>...</td>\n      <td>Closed with explanation</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2021-03-26T12:00:00-05:00</td>\n      <td>None</td>\n      <td>Checking account</td>\n      <td>Yes</td>\n      <td></td>\n      <td>Deposits and withdrawals</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>54478</th>\n      <td>complaint-public-v2</td>\n      <td>complaint</td>\n      <td>1344584</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1344584</td>\n      <td>Credit line increase/decrease</td>\n      <td>2015-04-23T12:00:00-05:00</td>\n      <td>CO</td>\n      <td>...</td>\n      <td>Closed with non-monetary relief</td>\n      <td>JPMORGAN CHASE &amp; CO.</td>\n      <td>Web</td>\n      <td>2015-04-23T12:00:00-05:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Yes</td>\n      <td>I have had several cards in good standing with...</td>\n      <td>None</td>\n      <td>Consent provided</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"(df.complaintwhathappened == \"\").sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:52.907366Z","iopub.execute_input":"2023-07-27T04:18:52.907689Z","iopub.status.idle":"2023-07-27T04:18:52.933541Z","shell.execute_reply.started":"2023-07-27T04:18:52.907643Z","shell.execute_reply":"2023-07-27T04:18:52.932319Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"57241"},"metadata":{}}]},{"cell_type":"code","source":"#Assign nan in place of blanks in the complaints column\ndf[df.complaintwhathappened == \"\"] = np.nan ","metadata":{"id":"grQUPFL5JrFx","execution":{"iopub.status.busy":"2023-07-27T04:18:52.936806Z","iopub.execute_input":"2023-07-27T04:18:52.937180Z","iopub.status.idle":"2023-07-27T04:18:53.041249Z","shell.execute_reply.started":"2023-07-27T04:18:52.937151Z","shell.execute_reply":"2023-07-27T04:18:53.040361Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"(df.complaintwhathappened == \"\").sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:53.042975Z","iopub.execute_input":"2023-07-27T04:18:53.043387Z","iopub.status.idle":"2023-07-27T04:18:53.059602Z","shell.execute_reply.started":"2023-07-27T04:18:53.043350Z","shell.execute_reply":"2023-07-27T04:18:53.058506Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"(df.complaintwhathappened == np.nan).sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:53.066017Z","iopub.execute_input":"2023-07-27T04:18:53.066997Z","iopub.status.idle":"2023-07-27T04:18:53.074069Z","shell.execute_reply.started":"2023-07-27T04:18:53.066964Z","shell.execute_reply":"2023-07-27T04:18:53.072978Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"#Remove all rows where complaints column is nan\ndf.dropna(subset=['complaintwhathappened'], inplace=True)","metadata":{"id":"Jfxd8VSmJrFy","execution":{"iopub.status.busy":"2023-07-27T04:18:53.075723Z","iopub.execute_input":"2023-07-27T04:18:53.076151Z","iopub.status.idle":"2023-07-27T04:18:53.139597Z","shell.execute_reply.started":"2023-07-27T04:18:53.076115Z","shell.execute_reply":"2023-07-27T04:18:53.138716Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:53.140968Z","iopub.execute_input":"2023-07-27T04:18:53.141292Z","iopub.status.idle":"2023-07-27T04:18:53.148477Z","shell.execute_reply.started":"2023-07-27T04:18:53.141264Z","shell.execute_reply":"2023-07-27T04:18:53.147403Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(21072, 22)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Prepare the text for topic modeling\n\nOnce you have removed all the blank complaints, you need to:\n\n* Make the text lowercase\n* Remove text in square brackets\n* Remove punctuation\n* Remove words containing numbers\n\n\nOnce you have done these cleaning operations you need to perform the following:\n* Lemmatize the texts\n* Extract the POS tags of the lemmatized text and remove all the words which have tags other than NN[tag == \"NN\"].\n","metadata":{"id":"L944HZpsJrFy"}},{"cell_type":"code","source":"# Write your function here to clean the text and remove all the unnecessary elements.\ndef clean_text(text):\n    # Make the text lowercase\n    text = text.lower()\n    \n    # Remove text in square brackets using regular expression\n    text = re.sub(r'\\[.*?\\]', '', text)\n    \n    # Remove punctuation using string library\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    \n    # Remove words containing numbers using regular expression\n    text = re.sub(r'\\w*\\d\\w*', '', text)\n    \n    return text","metadata":{"id":"qm7SjjSkJrFz","execution":{"iopub.status.busy":"2023-07-27T04:18:53.150541Z","iopub.execute_input":"2023-07-27T04:18:53.150950Z","iopub.status.idle":"2023-07-27T04:18:53.159591Z","shell.execute_reply.started":"2023-07-27T04:18:53.150913Z","shell.execute_reply":"2023-07-27T04:18:53.158705Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#Write your function to Lemmatize the texts\ndef lemmatize_text(text):\n    # Tokenize the text into words\n    words = word_tokenize(text.lower())\n    \n    # Initialize the WordNet Lemmatizer\n    lemmatizer = WordNetLemmatizer()\n    \n    # Lemmatize each word using its part of speech (POS)\n    lemmatized_words = []\n    for word, pos in nltk.pos_tag(words):\n        pos_letter = pos[0].lower() if pos[0].lower() in ['a', 'r', 'n', 'v'] else 'n'\n        lemma = lemmatizer.lemmatize(word, pos=pos_letter)\n        lemmatized_words.append(lemma)\n    \n    # Join the lemmatized words back into a sentence\n    lemmatized_text = ' '.join(lemmatized_words)\n    \n    return lemmatized_text","metadata":{"id":"zgOu8t8HJrFz","execution":{"iopub.status.busy":"2023-07-27T04:18:53.161300Z","iopub.execute_input":"2023-07-27T04:18:53.162142Z","iopub.status.idle":"2023-07-27T04:18:53.175706Z","shell.execute_reply.started":"2023-07-27T04:18:53.162113Z","shell.execute_reply":"2023-07-27T04:18:53.174900Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df['cleaned_complaints'] = df['complaintwhathappened'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:18:53.176689Z","iopub.execute_input":"2023-07-27T04:18:53.177018Z","iopub.status.idle":"2023-07-27T04:19:00.409586Z","shell.execute_reply.started":"2023-07-27T04:18:53.176991Z","shell.execute_reply":"2023-07-27T04:19:00.408195Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df['lemmatized_complaints'] = df['cleaned_complaints'].apply(lemmatize_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:19:00.410867Z","iopub.execute_input":"2023-07-27T04:19:00.411249Z","iopub.status.idle":"2023-07-27T04:25:32.315843Z","shell.execute_reply.started":"2023-07-27T04:19:00.411221Z","shell.execute_reply":"2023-07-27T04:25:32.314617Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df['lemmatized_complaints'].sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:25:32.317572Z","iopub.execute_input":"2023-07-27T04:25:32.318016Z","iopub.status.idle":"2023-07-27T04:25:32.327591Z","shell.execute_reply.started":"2023-07-27T04:25:32.317975Z","shell.execute_reply":"2023-07-27T04:25:32.326458Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"47877    cfpb please know that this be not a duplicate ...\n70796    chase clear a fraudlent check they do not even...\n11243    i recently apply for a chase credit card twice...\n30077    chase bank refuse to add my spouse to my check...\n19114    hello i be an authorized user on a relative ch...\n8548     im a recent xxxx and im try to save up some mo...\n22916    on unfortunately i deposit a fraudulent check ...\n26292    in xxxx i apply for deferred payment with my l...\n53843    i ask chase credit card service to close my ac...\n413      in regard to xxxx chase card service can someo...\nName: lemmatized_complaints, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#Create a dataframe('df_clean') that will have only the complaints and the lemmatized complaints \ndf_clean = pd.DataFrame(columns=['complaintwhathappened','lemmatized_complaints'], data=df[['complaintwhathappened','lemmatized_complaints']])","metadata":{"id":"uXnN7aa_JrF0","execution":{"iopub.status.busy":"2023-07-27T04:25:32.329092Z","iopub.execute_input":"2023-07-27T04:25:32.329498Z","iopub.status.idle":"2023-07-27T04:25:32.378848Z","shell.execute_reply.started":"2023-07-27T04:25:32.329469Z","shell.execute_reply":"2023-07-27T04:25:32.377577Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"nOiDVvEIJrF0","execution":{"iopub.status.busy":"2023-07-27T04:25:32.380409Z","iopub.execute_input":"2023-07-27T04:25:32.380765Z","iopub.status.idle":"2023-07-27T04:25:32.394101Z","shell.execute_reply.started":"2023-07-27T04:25:32.380735Z","shell.execute_reply":"2023-07-27T04:25:32.392957Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                   complaintwhathappened  \\\n1      Good morning my name is XXXX XXXX and I apprec...   \n2      I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n10     Chase Card was reported on XX/XX/2019. However...   \n11     On XX/XX/2018, while trying to book a XXXX  XX...   \n14     my grand son give me check for {$1600.00} i de...   \n...                                                  ...   \n78303  After being a Chase Card customer for well ove...   \n78309  On Wednesday, XX/XX/XXXX I called Chas, my XXX...   \n78310  I am not familiar with XXXX pay and did not un...   \n78311  I have had flawless credit for 30 yrs. I've ha...   \n78312  Roughly 10+ years ago I closed out my accounts...   \n\n                                   lemmatized_complaints  \n1      good morning my name be xxxx xxxx and i apprec...  \n2      i upgrade my xxxx xxxx card in and be tell by ...  \n10     chase card be report on however fraudulent app...  \n11     on while try to book a xxxx xxxx ticket i come...  \n14     my grand son give me check for i deposit it in...  \n...                                                  ...  \n78303  after be a chase card customer for well over a...  \n78309  on wednesday xxxxxxxx i call chas my xxxx xxxx...  \n78310  i be not familiar with xxxx pay and do not und...  \n78311  i have have flawless credit for yr ive have ch...  \n78312  roughly year ago i close out my account with j...  \n\n[21072 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>complaintwhathappened</th>\n      <th>lemmatized_complaints</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n      <td>good morning my name be xxxx xxxx and i apprec...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n      <td>i upgrade my xxxx xxxx card in and be tell by ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Chase Card was reported on XX/XX/2019. However...</td>\n      <td>chase card be report on however fraudulent app...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n      <td>on while try to book a xxxx xxxx ticket i come...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>my grand son give me check for {$1600.00} i de...</td>\n      <td>my grand son give me check for i deposit it in...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78303</th>\n      <td>After being a Chase Card customer for well ove...</td>\n      <td>after be a chase card customer for well over a...</td>\n    </tr>\n    <tr>\n      <th>78309</th>\n      <td>On Wednesday, XX/XX/XXXX I called Chas, my XXX...</td>\n      <td>on wednesday xxxxxxxx i call chas my xxxx xxxx...</td>\n    </tr>\n    <tr>\n      <th>78310</th>\n      <td>I am not familiar with XXXX pay and did not un...</td>\n      <td>i be not familiar with xxxx pay and do not und...</td>\n    </tr>\n    <tr>\n      <th>78311</th>\n      <td>I have had flawless credit for 30 yrs. I've ha...</td>\n      <td>i have have flawless credit for yr ive have ch...</td>\n    </tr>\n    <tr>\n      <th>78312</th>\n      <td>Roughly 10+ years ago I closed out my accounts...</td>\n      <td>roughly year ago i close out my account with j...</td>\n    </tr>\n  </tbody>\n</table>\n<p>21072 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Write your function to extract the POS tags \n\ndef get_pos_tag(text):\n    words = []\n    pos_tags = []\n  # write your code here\n    for word, pos in nltk.pos_tag(text):\n        words.append(word)\n        pos_tags.append(pos)\n    \n    return words, pos_tags\n\ndef remove_non_nn_words(text):\n    words, pos_tags = get_pos_tag(text)\n    sentence = ''\n    \n    for index, pos_tag in enumerate(pos_tags):\n        if pos_tag == 'NN':\n            sentence = sentence + ' ' + words[index]\n    return sentence\n","metadata":{"id":"Kk7fc4DuJrF1","execution":{"iopub.status.busy":"2023-07-27T04:44:21.689629Z","iopub.execute_input":"2023-07-27T04:44:21.690090Z","iopub.status.idle":"2023-07-27T04:44:21.698039Z","shell.execute_reply.started":"2023-07-27T04:44:21.690058Z","shell.execute_reply":"2023-07-27T04:44:21.696948Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_clean[\"complaint_POS_removed\"] =  df_clean['lemmatized_complaints'].apply(remove_non_nn_words)#this column should contain lemmatized text with all the words removed which have tags other than NN[tag == \"NN\"].","metadata":{"execution":{"iopub.status.busy":"2023-07-27T04:44:25.265335Z","iopub.execute_input":"2023-07-27T04:44:25.265764Z","iopub.status.idle":"2023-07-27T05:15:06.140027Z","shell.execute_reply.started":"2023-07-27T04:44:25.265729Z","shell.execute_reply":"2023-07-27T05:15:06.138398Z"},"trusted":true},"execution_count":31,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_clean[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplaint_POS_removed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m  \u001b[43mdf_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlemmatized_complaints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_non_nn_words\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#this column should contain lemmatized text with all the words removed which have tags other than NN[tag == \"NN\"].\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[30], line 14\u001b[0m, in \u001b[0;36mremove_non_nn_words\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_non_nn_words\u001b[39m(text):\n\u001b[0;32m---> 14\u001b[0m     words, pos_tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_pos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, pos_tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pos_tags):\n","Cell \u001b[0;32mIn[30], line 7\u001b[0m, in \u001b[0;36mget_pos_tag\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m   pos_tags \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# write your code here\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m word, pos \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      8\u001b[0m       words\u001b[38;5;241m.\u001b[39mappend(word)\n\u001b[1;32m      9\u001b[0m       pos_tags\u001b[38;5;241m.\u001b[39mappend(pos)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tag/__init__.py:127\u001b[0m, in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03mUse NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mtag the given list of tokens.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m:rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m tagger \u001b[38;5;241m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtagset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtagger\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tag/__init__.py:95\u001b[0m, in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pos_tag\u001b[39m(tokens, tagset, tagger):\n\u001b[0;32m---> 95\u001b[0m     tagged_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tagset:\n\u001b[1;32m     97\u001b[0m         tagged_tokens \u001b[38;5;241m=\u001b[39m [(token, map_tag(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-ptb\u001b[39m\u001b[38;5;124m'\u001b[39m, tagset, tag)) \u001b[38;5;28;01mfor\u001b[39;00m (token, tag) \u001b[38;5;129;01min\u001b[39;00m tagged_tokens]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tag/perceptron.py:157\u001b[0m, in \u001b[0;36mPerceptronTagger.tag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tag:\n\u001b[1;32m    156\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_features(i, word, context, prev, prev2)\n\u001b[0;32m--> 157\u001b[0m     tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m output\u001b[38;5;241m.\u001b[39mappend((word, tag))\n\u001b[1;32m    159\u001b[0m prev2 \u001b[38;5;241m=\u001b[39m prev\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tag/perceptron.py:56\u001b[0m, in \u001b[0;36mAveragedPerceptron.predict\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     54\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[feat]\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label, weight \u001b[38;5;129;01min\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 56\u001b[0m         scores[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m*\u001b[39m weight\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Do a secondary alphabetic sort, for stability\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m label: (scores[label], label))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#The clean dataframe should now contain the raw complaint, lemmatized complaint and the complaint after removing POS tags.\ndf_clean","metadata":{"id":"AjxfchvFJrF2","execution":{"iopub.status.busy":"2023-07-27T04:25:32.703122Z","iopub.status.idle":"2023-07-27T04:25:32.703532Z","shell.execute_reply.started":"2023-07-27T04:25:32.703339Z","shell.execute_reply":"2023-07-27T04:25:32.703358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory data analysis to get familiar with the data.\n\nWrite the code in this task to perform the following:\n\n*   Visualise the data according to the 'Complaint' character length\n*   Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n*   Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text. ‘\n\n\n","metadata":{"id":"_7Un1AElJrF2"}},{"cell_type":"code","source":"# Write your code here to visualise the data according to the 'Complaint' character length","metadata":{"id":"q-zaqJF6JrF2","execution":{"iopub.status.busy":"2023-07-27T04:25:32.705115Z","iopub.status.idle":"2023-07-27T04:25:32.705827Z","shell.execute_reply.started":"2023-07-27T04:25:32.705582Z","shell.execute_reply":"2023-07-27T04:25:32.705603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Find the top 40 words by frequency among all the articles after processing the text.","metadata":{"id":"T9jD_6SeJrF3"}},{"cell_type":"code","source":"#Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n","metadata":{"id":"QcfdvtfZJrF3","execution":{"iopub.status.busy":"2023-07-27T04:25:32.707067Z","iopub.status.idle":"2023-07-27T04:25:32.707476Z","shell.execute_reply.started":"2023-07-27T04:25:32.707289Z","shell.execute_reply":"2023-07-27T04:25:32.707308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing -PRON- from the text corpus\ndf_clean['Complaint_clean'] = df_clean['complaint_POS_removed'].str.replace('-PRON-', '')","metadata":{"id":"OkSmc3UaJrF4","execution":{"iopub.status.busy":"2023-07-27T04:25:32.708613Z","iopub.status.idle":"2023-07-27T04:25:32.709043Z","shell.execute_reply.started":"2023-07-27T04:25:32.708856Z","shell.execute_reply":"2023-07-27T04:25:32.708875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text.","metadata":{"id":"5DfCSbbmJrF4"}},{"cell_type":"code","source":"#Write your code here to find the top 30 unigram frequency among the complaints in the cleaned datafram(df_clean). \n","metadata":{"id":"5mbk5DS5JrF4","execution":{"iopub.status.busy":"2023-07-27T04:25:32.710407Z","iopub.status.idle":"2023-07-27T04:25:32.710873Z","shell.execute_reply.started":"2023-07-27T04:25:32.710605Z","shell.execute_reply":"2023-07-27T04:25:32.710630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the unigram frequency\n","metadata":{"id":"YX7fedm1JrF8","execution":{"iopub.status.busy":"2023-07-27T04:25:32.712130Z","iopub.status.idle":"2023-07-27T04:25:32.712502Z","shell.execute_reply.started":"2023-07-27T04:25:32.712327Z","shell.execute_reply":"2023-07-27T04:25:32.712344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your code here to find the top 30 bigram frequency among the complaints in the cleaned datafram(df_clean). \n","metadata":{"id":"aV7kD7w8JrF8","execution":{"iopub.status.busy":"2023-07-27T04:25:32.713629Z","iopub.status.idle":"2023-07-27T04:25:32.714100Z","shell.execute_reply.started":"2023-07-27T04:25:32.713905Z","shell.execute_reply":"2023-07-27T04:25:32.713923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the bigram frequency","metadata":{"id":"NPnMNIpyJrF9","execution":{"iopub.status.busy":"2023-07-27T04:25:32.715787Z","iopub.status.idle":"2023-07-27T04:25:32.716188Z","shell.execute_reply.started":"2023-07-27T04:25:32.715990Z","shell.execute_reply":"2023-07-27T04:25:32.716009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write your code here to find the top 30 trigram frequency among the complaints in the cleaned datafram(df_clean). \n","metadata":{"id":"Xkh7vtbtJrF-","execution":{"iopub.status.busy":"2023-07-27T04:25:32.717297Z","iopub.status.idle":"2023-07-27T04:25:32.717709Z","shell.execute_reply.started":"2023-07-27T04:25:32.717488Z","shell.execute_reply":"2023-07-27T04:25:32.717507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the top 10 words in the trigram frequency","metadata":{"id":"REcVxNfvJrF-","execution":{"iopub.status.busy":"2023-07-27T04:25:32.718998Z","iopub.status.idle":"2023-07-27T04:25:32.719381Z","shell.execute_reply.started":"2023-07-27T04:25:32.719194Z","shell.execute_reply":"2023-07-27T04:25:32.719212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The personal details of customer has been masked in the dataset with xxxx. Let's remove the masked text as this will be of no use for our analysis","metadata":{"id":"yUXzFji0JrF_"}},{"cell_type":"code","source":"df_clean['Complaint_clean'] = df_clean['Complaint_clean'].str.replace('xxxx','')","metadata":{"id":"wKda-a_IJrF_","execution":{"iopub.status.busy":"2023-07-27T04:25:32.720508Z","iopub.status.idle":"2023-07-27T04:25:32.720912Z","shell.execute_reply.started":"2023-07-27T04:25:32.720722Z","shell.execute_reply":"2023-07-27T04:25:32.720741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#All masked texts has been removed\ndf_clean","metadata":{"id":"9UIFk8fQJrF_","execution":{"iopub.status.busy":"2023-07-27T04:25:32.722025Z","iopub.status.idle":"2023-07-27T04:25:32.722426Z","shell.execute_reply.started":"2023-07-27T04:25:32.722226Z","shell.execute_reply":"2023-07-27T04:25:32.722245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction\nConvert the raw texts to a matrix of TF-IDF features\n\n**max_df** is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\"\nmax_df = 0.95 means \"ignore terms that appear in more than 95% of the complaints\"\n\n**min_df** is used for removing terms that appear too infrequently\nmin_df = 2 means \"ignore terms that appear in less than 2 complaints\"","metadata":{"id":"k-I0k0QtJrGA"}},{"cell_type":"code","source":"#Write your code here to initialise the TfidfVectorizer \n\n","metadata":{"id":"Y8fGwaCPJrGA","execution":{"iopub.status.busy":"2023-07-27T04:25:32.724291Z","iopub.status.idle":"2023-07-27T04:25:32.724693Z","shell.execute_reply.started":"2023-07-27T04:25:32.724481Z","shell.execute_reply":"2023-07-27T04:25:32.724499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create a document term matrix using fit_transform\n\nThe contents of a document term matrix are tuples of (complaint_id,token_id) tf-idf score:\nThe tuples that are not there have a tf-idf score of 0","metadata":{"id":"yYzD85nTJrGA"}},{"cell_type":"code","source":"#Write your code here to create the Document Term Matrix by transforming the complaints column present in df_clean.\n","metadata":{"id":"ffzdDpp_JrGB","execution":{"iopub.status.busy":"2023-07-27T04:25:32.726162Z","iopub.status.idle":"2023-07-27T04:25:32.726557Z","shell.execute_reply.started":"2023-07-27T04:25:32.726361Z","shell.execute_reply":"2023-07-27T04:25:32.726379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Topic Modelling using NMF\n\nNon-Negative Matrix Factorization (NMF) is an unsupervised technique so there are no labeling of topics that the model will be trained on. The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative.\n\nIn this task you have to perform the following:\n\n* Find the best number of clusters \n* Apply the best number to create word clusters\n* Inspect & validate the correction of each cluster wrt the complaints \n* Correct the labels if needed \n* Map the clusters to topics/cluster names","metadata":{"id":"7Q9lwvNEJrGB"}},{"cell_type":"code","source":"from sklearn.decomposition import NMF","metadata":{"id":"amLT4omWJrGB","execution":{"iopub.status.busy":"2023-07-27T04:25:32.728459Z","iopub.status.idle":"2023-07-27T04:25:32.728878Z","shell.execute_reply.started":"2023-07-27T04:25:32.728680Z","shell.execute_reply":"2023-07-27T04:25:32.728705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Manual Topic Modeling\nYou need to do take the trial & error approach to find the best num of topics for your NMF model.\n\nThe only parameter that is required is the number of components i.e. the number of topics we want. This is the most crucial step in the whole topic modeling process and will greatly affect how good your final topics are.","metadata":{"id":"0wYR1xUTJrGD"}},{"cell_type":"code","source":"#Load your nmf_model with the n_components i.e 5\nnum_topics = #write the value you want to test out\n\n#keep the random_state =40\nnmf_model = #write your code here","metadata":{"id":"sgd2A6bhJrGD","execution":{"iopub.status.busy":"2023-07-27T04:25:32.730610Z","iopub.status.idle":"2023-07-27T04:25:32.731051Z","shell.execute_reply.started":"2023-07-27T04:25:32.730854Z","shell.execute_reply":"2023-07-27T04:25:32.730874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nmf_model.fit(dtm)\nlen(tfidf.get_feature_names())","metadata":{"id":"VPMDYbt_JrGE","execution":{"iopub.status.busy":"2023-07-27T04:25:32.732620Z","iopub.status.idle":"2023-07-27T04:25:32.733066Z","shell.execute_reply.started":"2023-07-27T04:25:32.732877Z","shell.execute_reply":"2023-07-27T04:25:32.732896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the Top15 words for each of the topics\n","metadata":{"id":"16kRfat5JrGE","execution":{"iopub.status.busy":"2023-07-27T04:25:32.734958Z","iopub.status.idle":"2023-07-27T04:25:32.735357Z","shell.execute_reply.started":"2023-07-27T04:25:32.735162Z","shell.execute_reply":"2023-07-27T04:25:32.735182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create the best topic for each complaint in terms of integer value 0,1,2,3 & 4\n\n","metadata":{"id":"0OIT7LmFJrGF","execution":{"iopub.status.busy":"2023-07-27T04:25:32.736649Z","iopub.status.idle":"2023-07-27T04:25:32.737072Z","shell.execute_reply.started":"2023-07-27T04:25:32.736881Z","shell.execute_reply":"2023-07-27T04:25:32.736901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assign the best topic to each of the cmplaints in Topic Column\n\ndf_clean['Topic'] = #write your code to assign topics to each rows.","metadata":{"id":"peyYv-ORJrGF","execution":{"iopub.status.busy":"2023-07-27T04:25:32.738303Z","iopub.status.idle":"2023-07-27T04:25:32.738731Z","shell.execute_reply.started":"2023-07-27T04:25:32.738502Z","shell.execute_reply":"2023-07-27T04:25:32.738521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean.head()","metadata":{"id":"fLh_Gf3nJrGF","execution":{"iopub.status.busy":"2023-07-27T04:25:32.740748Z","iopub.status.idle":"2023-07-27T04:25:32.741170Z","shell.execute_reply.started":"2023-07-27T04:25:32.740939Z","shell.execute_reply":"2023-07-27T04:25:32.740956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the first 5 Complaint for each of the Topics\ndf_clean=df_clean.groupby('Topic').head(5)\ndf_clean.sort_values('Topic')","metadata":{"id":"aQKpufSPJrGG","execution":{"iopub.status.busy":"2023-07-27T04:25:32.742845Z","iopub.status.idle":"2023-07-27T04:25:32.743245Z","shell.execute_reply.started":"2023-07-27T04:25:32.743046Z","shell.execute_reply":"2023-07-27T04:25:32.743065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### After evaluating the mapping, if the topics assigned are correct then assign these names to the relevant topic:\n* Bank Account services\n* Credit card or prepaid card\n* Theft/Dispute Reporting\n* Mortgage/Loan\n* Others","metadata":{"id":"piyLxzj6v07j"}},{"cell_type":"code","source":"#Create the dictionary of Topic names and Topics\n\nTopic_names = {   }\n#Replace Topics with Topic Names\ndf_clean['Topic'] = df_clean['Topic'].map(Topic_names)","metadata":{"id":"TWpwDG4RJrGG","execution":{"iopub.status.busy":"2023-07-27T04:25:32.744585Z","iopub.status.idle":"2023-07-27T04:25:32.745433Z","shell.execute_reply.started":"2023-07-27T04:25:32.745208Z","shell.execute_reply":"2023-07-27T04:25:32.745240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"-2ULY5K6JrGG","execution":{"iopub.status.busy":"2023-07-27T04:25:32.746972Z","iopub.status.idle":"2023-07-27T04:25:32.747381Z","shell.execute_reply.started":"2023-07-27T04:25:32.747180Z","shell.execute_reply":"2023-07-27T04:25:32.747199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supervised model to predict any new complaints to the relevant Topics.\n\nYou have now build the model to create the topics for each complaints.Now in the below section you will use them to classify any new complaints.\n\nSince you will be using supervised learning technique we have to convert the topic names to numbers(numpy arrays only understand numbers)","metadata":{"id":"7Mu0QBOcJrGH"}},{"cell_type":"code","source":"#Create the dictionary again of Topic names and Topics\n\nTopic_names = {   }\n#Replace Topics with Topic Names\ndf_clean['Topic'] = df_clean['Topic'].map(Topic_names)","metadata":{"id":"_U8J3J8wJrGH","execution":{"iopub.status.busy":"2023-07-27T04:25:32.748905Z","iopub.status.idle":"2023-07-27T04:25:32.749307Z","shell.execute_reply.started":"2023-07-27T04:25:32.749106Z","shell.execute_reply":"2023-07-27T04:25:32.749133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean","metadata":{"id":"BWIgJUkQJrGH","execution":{"iopub.status.busy":"2023-07-27T04:25:32.752572Z","iopub.status.idle":"2023-07-27T04:25:32.753500Z","shell.execute_reply.started":"2023-07-27T04:25:32.753210Z","shell.execute_reply":"2023-07-27T04:25:32.753260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Keep the columns\"complaint_what_happened\" & \"Topic\" only in the new dataframe --> training_data\ntraining_data=","metadata":{"id":"Xx-FrbkWJrGH","execution":{"iopub.status.busy":"2023-07-27T04:25:32.755233Z","iopub.status.idle":"2023-07-27T04:25:32.755635Z","shell.execute_reply.started":"2023-07-27T04:25:32.755435Z","shell.execute_reply":"2023-07-27T04:25:32.755454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data","metadata":{"id":"lVg2pa12JrGI","execution":{"iopub.status.busy":"2023-07-27T04:25:32.756753Z","iopub.status.idle":"2023-07-27T04:25:32.757155Z","shell.execute_reply.started":"2023-07-27T04:25:32.756952Z","shell.execute_reply":"2023-07-27T04:25:32.756971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####Apply the supervised models on the training data created. In this process, you have to do the following:\n* Create the vector counts using Count Vectoriser\n* Transform the word vecotr to tf-idf\n* Create the train & test data using the train_test_split on the tf-idf & topics\n","metadata":{"id":"280Vbqk-7a8M"}},{"cell_type":"code","source":"\n#Write your code to get the Vector count\n\n\n#Write your code here to transform the word vector to tf-idf","metadata":{"id":"oUlQpgkzJrGI","execution":{"iopub.status.busy":"2023-07-27T04:25:32.759001Z","iopub.status.idle":"2023-07-27T04:25:32.759343Z","shell.execute_reply.started":"2023-07-27T04:25:32.759169Z","shell.execute_reply":"2023-07-27T04:25:32.759186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You have to try atleast 3 models on the train & test data from these options:\n* Logistic regression\n* Decision Tree\n* Random Forest\n* Naive Bayes (optional)\n\n**Using the required evaluation metrics judge the tried models and select the ones performing the best**","metadata":{"id":"uMU3vj6w-wqL"}},{"cell_type":"code","source":"# Write your code here to build any 3 models and evaluate them using the required metrics\n\n\n\n","metadata":{"id":"udLHpPsZJrGI","execution":{"iopub.status.busy":"2023-07-27T04:25:32.761456Z","iopub.status.idle":"2023-07-27T04:25:32.761882Z","shell.execute_reply.started":"2023-07-27T04:25:32.761677Z","shell.execute_reply":"2023-07-27T04:25:32.761704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"N2OznsObJrGP"},"execution_count":null,"outputs":[]}]}