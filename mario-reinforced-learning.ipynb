{"metadata":{"kernelspec":{"display_name":"mario","language":"python","name":"mario"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Setup Mario","metadata":{}},{"cell_type":"code","source":"!pip install gym_super_mario_bros==7.3.0 nes_py","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the game\nimport gym_super_mario_bros\n# Import the Joypad wrapper\nfrom nes_py.wrappers import JoypadSpace\n# Import the SIMPLIFIED controls\nfrom gym_super_mario_bros.actions import SIMPLE_MOVEMENT","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup game\nenv = gym_super_mario_bros.make('SuperMarioBros-v0')\nenv = JoypadSpace(env, SIMPLE_MOVEMENT)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a flag - restart or not\ndone = True\n# Loop through each frame in the game\nfor step in range(100000): \n    # Start the game to begin with \n    if done: \n        # Start the gamee\n        env.reset()\n    # Do random actions\n    state, reward, done, info = env.step(env.action_space.sample())\n    # Show the game on the screen\n    env.render()\n# Close the game\nenv.close()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Preprocess Environment","metadata":{}},{"cell_type":"code","source":"# Install pytorch\n!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install stable baselines for RL stuff\n!pip install stable-baselines3[extra]","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Frame Stacker Wrapper and GrayScaling Wrapper\nfrom gym.wrappers import GrayScaleObservation\n# Import Vectorization Wrappers\nfrom stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n# Import Matplotlib to show the impact of frame stacking\nfrom matplotlib import pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Create the base environment\nenv = gym_super_mario_bros.make('SuperMarioBros-v0')\n# 2. Simplify the controls \nenv = JoypadSpace(env, SIMPLE_MOVEMENT)\n# 3. Grayscale\nenv = GrayScaleObservation(env, keep_dim=True)\n# 4. Wrap inside the Dummy Environment\nenv = DummyVecEnv([lambda: env])\n# 5. Stack the frames\nenv = VecFrameStack(env, 4, channels_order='last')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state = env.reset()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state, reward, done, info = env.step([5])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,16))\nfor idx in range(state.shape[3]):\n    plt.subplot(1,4,idx+1)\n    plt.imshow(state[0][:,:,idx])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Train the RL Model","metadata":{}},{"cell_type":"code","source":"# Import os for file path management\nimport os \n# Import PPO for algos\nfrom stable_baselines3 import PPO\n# Import Base Callback for saving models\nfrom stable_baselines3.common.callbacks import BaseCallback","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainAndLoggingCallback(BaseCallback):\n\n    def __init__(self, check_freq, save_path, verbose=1):\n        super(TrainAndLoggingCallback, self).__init__(verbose)\n        self.check_freq = check_freq\n        self.save_path = save_path\n\n    def _init_callback(self):\n        if self.save_path is not None:\n            os.makedirs(self.save_path, exist_ok=True)\n\n    def _on_step(self):\n        if self.n_calls % self.check_freq == 0:\n            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n            self.model.save(model_path)\n\n        return True","metadata":{"tags":[],"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CHECKPOINT_DIR = './train/'\nLOG_DIR = './logs/'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup model saving callback\ncallback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)","metadata":{"tags":[],"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is the AI model started\nmodel = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, \n            n_steps=512) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the AI model, this is where the AI model starts to learn\nmodel.learn(total_timesteps=1000000, callback=callback)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('thisisatestmodel')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Test it Out","metadata":{}},{"cell_type":"code","source":"# Load model\nmodel = PPO.load('./train/best_model_1000000')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state = env.reset()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start the game \nstate = env.reset()\n# Loop through the game\nwhile True: \n    \n    action, _ = model.predict(state)\n    state, reward, done, info = env.step(action)\n    env.render()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}